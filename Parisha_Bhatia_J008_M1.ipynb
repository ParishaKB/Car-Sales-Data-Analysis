{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parisha Bhatia_J008_M1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3t+cWouU5vVI9o7DsWf/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParishaKB/Car-Sales-Data-Analysis/blob/master/Parisha_Bhatia_J008_M1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUuFOMYs8Al6",
        "colab_type": "text"
      },
      "source": [
        "Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJd7DJ17W_Xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b6438c30-d136-4b7e-8b82-c78259e62223"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(27)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omnXwG6h8LNM",
        "colab_type": "text"
      },
      "source": [
        "Setting plot parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIdNROyrXWfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up default plotting parameters\n",
        "%matplotlib inline\n",
        "#fix figure size\n",
        "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
        "#fix font size\n",
        "plt.rcParams.update({'font.size': 22,})\n",
        "#fix colour/style/font\n",
        "sns.set_palette('viridis')\n",
        "sns.set_style('white')\n",
        "sns.set_context('talk', font_scale=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVpvOEV78RJa",
        "colab_type": "text"
      },
      "source": [
        "Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEqlPo_qXYUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7f9Otue8S1h",
        "colab_type": "text"
      },
      "source": [
        "Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-U0y1khXweN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "ca91022b-f9f9-4c55-b780-194d3c43ad03"
      },
      "source": [
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(891, 12)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMibvf8RYAnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "91615b73-0591-4240-846f-8682a4bae7cd"
      },
      "source": [
        "train.describe(include = 'all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891</td>\n",
              "      <td>891</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>204</td>\n",
              "      <td>889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>891</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>681</td>\n",
              "      <td>NaN</td>\n",
              "      <td>147</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Carlsson, Mr. August Sigfrid</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>347082</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>577</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.204208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>NaN</td>\n",
              "      <td>49.693429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.910400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.454200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>512.329200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PassengerId    Survived      Pclass  ...        Fare    Cabin  Embarked\n",
              "count    891.000000  891.000000  891.000000  ...  891.000000      204       889\n",
              "unique          NaN         NaN         NaN  ...         NaN      147         3\n",
              "top             NaN         NaN         NaN  ...         NaN  B96 B98         S\n",
              "freq            NaN         NaN         NaN  ...         NaN        4       644\n",
              "mean     446.000000    0.383838    2.308642  ...   32.204208      NaN       NaN\n",
              "std      257.353842    0.486592    0.836071  ...   49.693429      NaN       NaN\n",
              "min        1.000000    0.000000    1.000000  ...    0.000000      NaN       NaN\n",
              "25%      223.500000    0.000000    2.000000  ...    7.910400      NaN       NaN\n",
              "50%      446.000000    0.000000    3.000000  ...   14.454200      NaN       NaN\n",
              "75%      668.500000    1.000000    3.000000  ...   31.000000      NaN       NaN\n",
              "max      891.000000    1.000000    3.000000  ...  512.329200      NaN       NaN\n",
              "\n",
              "[11 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDC83WTh8YZr",
        "colab_type": "text"
      },
      "source": [
        "# **Q1) Handling null values**\n",
        "\n",
        "Check number of null values in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyhBTugiY16P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ce32ec37-b1d9-4b4f-8642-e8d58ddbc7bb"
      },
      "source": [
        "train.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaQ0E9J88thm",
        "colab_type": "text"
      },
      "source": [
        "Replace null of embarked with max occuring value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH1PAx0dZ7J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Embarked'].value_counts()\n",
        "train['Embarked'].replace(np.nan, 'S', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teC4kxGr81IS",
        "colab_type": "text"
      },
      "source": [
        "Drop Cabin column since there are more than 50% of null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8dwTn2xe3B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(['Cabin'],axis = 1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dcJtFGi9MC2",
        "colab_type": "text"
      },
      "source": [
        "Replace na values with mean for numeric column : Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQIHw0zDfMhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Age'].fillna(train['Age'].mean(), inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_DbRRfb9Tgy",
        "colab_type": "text"
      },
      "source": [
        "Check percent of null values for each column for verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urVxOcYPdp00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "5bc4ece1-34ee-464f-e909-f10655b4a3f3"
      },
      "source": [
        "percent_missing = train.isnull().sum() * 100 / len(train)\n",
        "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
        "missing_value_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>percent_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticket</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             percent_missing\n",
              "PassengerId              0.0\n",
              "Survived                 0.0\n",
              "Pclass                   0.0\n",
              "Name                     0.0\n",
              "Sex                      0.0\n",
              "Age                      0.0\n",
              "SibSp                    0.0\n",
              "Parch                    0.0\n",
              "Ticket                   0.0\n",
              "Fare                     0.0\n",
              "Embarked                 0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyfU1ZP_wuIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "c843e0c2-59e6-47d5-de91-fef0e689951d"
      },
      "source": [
        "corr= train.corr()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "cax = ax.matshow(corr, cmap='coolwarm')\n",
        "fig.colorbar(cax)\n",
        "ticks = np.arange(0,len(corr.columns),1)\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xticklabels(corr.columns)\n",
        "ax.set_yticklabels(corr.columns)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSD_w6DNgvTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9f8c39a7-dd42-439a-e187-85247e5a78e2"
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Survived         int64\n",
              "Pclass           int64\n",
              "Name            object\n",
              "Sex             object\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Ticket          object\n",
              "Fare           float64\n",
              "Embarked        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxg_TNRCkXHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "4977964e-e143-4d40-943d-c61f9d914c01"
      },
      "source": [
        "#drop passengerid\n",
        "train.drop(['PassengerId'],axis = 1,inplace=True)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  ...     Fare Embarked\n",
              "0         0       3  ...   7.2500        S\n",
              "1         1       1  ...  71.2833        C\n",
              "2         1       3  ...   7.9250        S\n",
              "3         1       1  ...  53.1000        S\n",
              "4         0       3  ...   8.0500        S\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIiJ2LPKhXzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "0051fe45-3d35-4e41-f733-6deb8a86fa1d"
      },
      "source": [
        "P_Class_dummies = pd.get_dummies(train['Pclass'])\n",
        "P_Class_dummies.columns = ['PClass1','PClass2','PClass3']\n",
        "train = pd.concat([train.drop('Pclass',axis = 1),P_Class_dummies],axis = 1)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>PClass1</th>\n",
              "      <th>PClass2</th>\n",
              "      <th>PClass3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  ... PClass3\n",
              "0         0  ...       1\n",
              "1         1  ...       0\n",
              "2         1  ...       1\n",
              "3         1  ...       0\n",
              "4         0  ...       1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ICXchiqm6CZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "f5c5f13d-676e-4626-a11b-638b00979bd2"
      },
      "source": [
        "S_dummies = pd.get_dummies(train['Sex'])\n",
        "S_dummies.columns = ['male','female']\n",
        "train = pd.concat([train.drop('Sex',axis = 1),S_dummies],axis = 1)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>PClass1</th>\n",
              "      <th>PClass2</th>\n",
              "      <th>PClass3</th>\n",
              "      <th>male</th>\n",
              "      <th>female</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived                                               Name  ...  male  female\n",
              "0         0                            Braund, Mr. Owen Harris  ...     0       1\n",
              "1         1  Cumings, Mrs. John Bradley (Florence Briggs Th...  ...     1       0\n",
              "2         1                             Heikkinen, Miss. Laina  ...     1       0\n",
              "3         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  ...     1       0\n",
              "4         0                           Allen, Mr. William Henry  ...     0       1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrOgHpTCfa5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "99d22dc4-466b-436f-b29a-686c9a8fd5fd"
      },
      "source": [
        "# Create column family survived & died from column 'Name' (LastName)\n",
        "train['LastName'] = train['Name'].str.split(',', expand=True)[0]\n",
        "train[train['SibSp'] == 4]\n",
        "train['Train'] = 1\n",
        "alldata = train\n",
        "sur_data = []\n",
        "died_data = []\n",
        "for index, row in alldata.iterrows():\n",
        "    s = alldata[(alldata['LastName']==row['LastName']) & (alldata['Survived']==1)]\n",
        "    d = alldata[(alldata['LastName']==row['LastName']) & (alldata['Survived']==0)]\n",
        "    \n",
        "    s=len(s)\n",
        "    if row['Survived'] == 1:\n",
        "        s-=1\n",
        "\n",
        "    d=len(d)\n",
        "    if row['Survived'] == 0:\n",
        "        d-=1\n",
        "        \n",
        "    sur_data.append(s)\n",
        "    died_data.append(d)\n",
        "    \n",
        "alldata['FamilySurvived'] = sur_data\n",
        "alldata['FamilyDied'] = died_data\n",
        "alldata.dtypes\n",
        "X = alldata[['Age', 'SibSp', 'Parch', 'Fare','PClass1', 'PClass2', 'PClass3', 'male', 'female','FamilySurvived', 'FamilyDied']]\n",
        "X.head()\n",
        "Y = alldata[['Survived']]\n",
        "clean_data = pd.concat([X,Y],axis = 1)\n",
        "clean_data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>PClass1</th>\n",
              "      <th>PClass2</th>\n",
              "      <th>PClass3</th>\n",
              "      <th>male</th>\n",
              "      <th>female</th>\n",
              "      <th>FamilySurvived</th>\n",
              "      <th>FamilyDied</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  SibSp  Parch     Fare  ...  female  FamilySurvived  FamilyDied  Survived\n",
              "0  22.0      1      0   7.2500  ...       1               0           1         0\n",
              "1  38.0      1      0  71.2833  ...       0               0           0         1\n",
              "2  26.0      0      0   7.9250  ...       0               0           0         1\n",
              "3  35.0      1      0  53.1000  ...       0               0           1         1\n",
              "4  35.0      0      0   8.0500  ...       1               1           0         0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZaDcylynFyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(train[['Age', 'SibSp', 'Parch', 'Fare']])\n",
        "train[['Age', 'SibSp', 'Parch', 'Fare']] = sc.transform(train[['Age', 'SibSp', 'Parch', 'Fare']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri3XsrSTlzl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "31dd34dc-85bd-46b8-a708-2a171e0fff88"
      },
      "source": [
        "#drop passengerid\n",
        "train.drop(['Ticket'],axis = 1,inplace=True)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>PClass1</th>\n",
              "      <th>PClass2</th>\n",
              "      <th>PClass3</th>\n",
              "      <th>male</th>\n",
              "      <th>female</th>\n",
              "      <th>LastName</th>\n",
              "      <th>Train</th>\n",
              "      <th>FamilySurvived</th>\n",
              "      <th>FamilyDied</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>-0.592481</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>-0.502445</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Braund</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0.638789</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>0.786845</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Cumings</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>-0.284663</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>-0.488854</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Heikkinen</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0.407926</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>0.420730</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Futrelle</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>0.407926</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>-0.486337</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Allen</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  ... FamilyDied\n",
              "0         0  ...          1\n",
              "1         1  ...          0\n",
              "2         1  ...          0\n",
              "3         1  ...          1\n",
              "4         0  ...          0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcjwoeLHxrst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "53e1a066-9bb1-474c-ca28-c64ee4df39d2"
      },
      "source": [
        "corr= clean_data.corr()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "cax = ax.matshow(corr, cmap='coolwarm')\n",
        "fig.colorbar(cax)\n",
        "ticks = np.arange(0,len(corr.columns),1)\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xticklabels(corr.columns)\n",
        "ax.set_yticklabels(corr.columns)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgazjg7of49H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "37b21703-ef08-4fc2-c378-a2a77b628557"
      },
      "source": [
        "X = alldata[['Age', 'SibSp', 'Parch', 'Fare','PClass1', 'PClass2', 'PClass3', 'female','FamilySurvived', 'FamilyDied']]\n",
        "X.head()\n",
        "Y = alldata[['Survived']]\n",
        "seed = 7\n",
        "test_size = 0.4\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size= 0.5, random_state=seed)\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "#use ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySurvived','FamilyDied'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(534, 10)\n",
            "(178, 10)\n",
            "(179, 10)\n",
            "(534, 1)\n",
            "(178, 1)\n",
            "(179, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym1NIGOZsxWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "d6a079b3-759a-4f94-9188-ab7e20a5025a"
      },
      "source": [
        "# define models\n",
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "logistic = linear_model.LogisticRegression(solver='liblinear')\n",
        "sgd = linear_model.SGDClassifier()\n",
        "models = [logistic, sgd,dtree]\n",
        "# function to get cross validation scores\n",
        "def get_cv_scores(model):\n",
        "    scores = cross_val_score(model, x_train, y_train, cv=5, scoring='roc_auc')\n",
        "    print('CV Mean: ', np.mean(scores))\n",
        "    print('STD: ', np.std(scores))\n",
        "    print('\\n')\n",
        "# loop through list of models\n",
        "for model in models:\n",
        "    print(model)\n",
        "    get_cv_scores(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "CV Mean:  0.8798665045811666\n",
            "STD:  0.02608304068957099\n",
            "\n",
            "\n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "CV Mean:  0.8425930303234959\n",
            "STD:  0.020263757618409522\n",
            "\n",
            "\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "CV Mean:  0.796179172013237\n",
            "STD:  0.03512901928199602\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRj58GRatKx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7940c3c4-fc7a-404f-87cb-95458ae10a8a"
      },
      "source": [
        "penalty = ['l1', 'l2']\n",
        "C = [0.0001, 0.001, 0.01]\n",
        "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}]\n",
        "solver = ['liblinear', 'saga']\n",
        "\n",
        "param_grid = dict(penalty=penalty,\n",
        "                  C=C,\n",
        "                  class_weight=class_weight,\n",
        "                  solver=solver)\n",
        "\n",
        "grid = GridSearchCV(estimator=logistic, param_grid=param_grid, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "print('Best Score: ', grid_result.best_score_)\n",
        "print('Best Params: ', grid_result.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.7247751719273496\n",
            "Best Params:  {'C': 0.01, 'class_weight': {1: 0.5, 0: 0.5}, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzKV0bDttW8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e96db461-f450-4e97-85a0-b9e2cf05c8f8"
      },
      "source": [
        "logistic = linear_model.LogisticRegression(C=0.0001, class_weight={1:0.5, 0:0.5}, penalty='l2', solver='liblinear')\n",
        "get_cv_scores(logistic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Mean:  0.8485440444834651\n",
            "STD:  0.02713132783085252\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUhM_GletW2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "573a9b3d-4d78-4e6c-8412-f62c9816c89a"
      },
      "source": [
        "loss = ['hinge', 'log']\n",
        "penalty = ['l1', 'l2']\n",
        "alpha = [0.0001, 0.001]\n",
        "learning_rate = ['constant', 'optimal']\n",
        "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}]\n",
        "eta0 = [1, 10]\n",
        "\n",
        "param_distributions = dict(loss=loss,\n",
        "                           penalty=penalty,\n",
        "                           alpha=alpha,\n",
        "                           learning_rate=learning_rate,\n",
        "                           class_weight=class_weight,\n",
        "                           eta0=eta0)\n",
        "\n",
        "random = RandomizedSearchCV(estimator=sgd, param_distributions=param_distributions, scoring='accuracy', verbose=1, n_jobs=-1, n_iter=1000)\n",
        "random_result = random.fit(x_train, y_train)\n",
        "\n",
        "print('Best Score: ', random_result.best_score_)\n",
        "print('Best Params: ', random_result.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.8407688238405925\n",
            "Best Params:  {'penalty': 'l1', 'loss': 'log', 'learning_rate': 'optimal', 'eta0': 1, 'class_weight': {1: 0.5, 0: 0.5}, 'alpha': 0.001}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    1.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1naiql5CtkH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4b70a329-4af5-456a-8f8f-8a355eba7f68"
      },
      "source": [
        "sgd = linear_model.SGDClassifier(alpha=0.001,\n",
        "                                 class_weight={1:0.4, 0:0.6},\n",
        "                                 eta0=1,\n",
        "                                 learning_rate='optimal',\n",
        "                                 loss='hinge',\n",
        "                                 penalty='l1')\n",
        "get_cv_scores(sgd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV Mean:  0.8560196753787623\n",
            "STD:  0.03962012473250476\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j07q_9qmtkFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "21b832ba-03cf-4f1b-fd44-71be80324441"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "sgd.fit(x_train, y_train)\n",
        "\n",
        "y_train_pred = sgd.predict(x_train)\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_train*100))\n",
        "\n",
        "\n",
        "y_test_pred = sgd.predict(x_test)\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_test*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 83.33%\n",
            "Accuracy: 75.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpGnzKIm5Erq",
        "colab_type": "text"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ATlAoW75IDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7cb60941-b983-4604-a52c-b66fc113f0f9"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "nn=models.Sequential()\n",
        "nn.add(layers.Dense(1024,activation = \"relu\",input_shape=(10,))) \n",
        "nn.add(layers.Dense(512,activation='relu'))\n",
        "nn.add(layers.Dense(256,activation='relu'))\n",
        "nn.add(layers.Dense(128,activation='relu'))\n",
        "nn.add(layers.Dense(1,activation='sigmoid'))\n",
        "nn.summary()\n",
        "nn.compile(optimizer=\"rmsprop\",loss='binary_crossentropy',metrics = ['accuracy'])\n",
        "nn.fit(X,Y, epochs=1000, validation_split=0.16)\n",
        "test_loss,test_acc=nn.evaluate(x_test,y_test)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              11264     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 700,417\n",
            "Trainable params: 700,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.5380 - accuracy: 0.7406 - val_loss: 0.4087 - val_accuracy: 0.8392\n",
            "Epoch 2/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8048 - val_loss: 0.3624 - val_accuracy: 0.8531\n",
            "Epoch 3/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8249 - val_loss: 0.3916 - val_accuracy: 0.8671\n",
            "Epoch 4/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8316 - val_loss: 0.4220 - val_accuracy: 0.8671\n",
            "Epoch 5/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8382 - val_loss: 0.3713 - val_accuracy: 0.8601\n",
            "Epoch 6/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8356 - val_loss: 0.3680 - val_accuracy: 0.8601\n",
            "Epoch 7/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8369 - val_loss: 0.4293 - val_accuracy: 0.8741\n",
            "Epoch 8/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8396 - val_loss: 0.4264 - val_accuracy: 0.8601\n",
            "Epoch 9/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8409 - val_loss: 0.3963 - val_accuracy: 0.8601\n",
            "Epoch 10/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8396 - val_loss: 0.3774 - val_accuracy: 0.8671\n",
            "Epoch 11/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8489 - val_loss: 0.4143 - val_accuracy: 0.8531\n",
            "Epoch 12/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8463 - val_loss: 0.3491 - val_accuracy: 0.8741\n",
            "Epoch 13/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8463 - val_loss: 0.3391 - val_accuracy: 0.8601\n",
            "Epoch 14/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8529 - val_loss: 0.4401 - val_accuracy: 0.8462\n",
            "Epoch 15/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8623 - val_loss: 0.4322 - val_accuracy: 0.8741\n",
            "Epoch 16/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8690 - val_loss: 0.4498 - val_accuracy: 0.8671\n",
            "Epoch 17/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8610 - val_loss: 0.3934 - val_accuracy: 0.8951\n",
            "Epoch 18/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8690 - val_loss: 0.5427 - val_accuracy: 0.8601\n",
            "Epoch 19/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.8676 - val_loss: 0.4427 - val_accuracy: 0.8671\n",
            "Epoch 20/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8730 - val_loss: 0.3692 - val_accuracy: 0.8601\n",
            "Epoch 21/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8770 - val_loss: 0.5804 - val_accuracy: 0.8462\n",
            "Epoch 22/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8610 - val_loss: 0.4877 - val_accuracy: 0.8881\n",
            "Epoch 23/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8783 - val_loss: 0.5005 - val_accuracy: 0.8601\n",
            "Epoch 24/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8757 - val_loss: 0.4713 - val_accuracy: 0.8741\n",
            "Epoch 25/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8730 - val_loss: 0.5566 - val_accuracy: 0.8601\n",
            "Epoch 26/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8797 - val_loss: 0.5095 - val_accuracy: 0.8671\n",
            "Epoch 27/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8783 - val_loss: 0.5730 - val_accuracy: 0.8531\n",
            "Epoch 28/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.8783 - val_loss: 0.5972 - val_accuracy: 0.8601\n",
            "Epoch 29/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8824 - val_loss: 0.5364 - val_accuracy: 0.8601\n",
            "Epoch 30/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8783 - val_loss: 0.5993 - val_accuracy: 0.8671\n",
            "Epoch 31/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8783 - val_loss: 0.6504 - val_accuracy: 0.8741\n",
            "Epoch 32/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8757 - val_loss: 0.5654 - val_accuracy: 0.8531\n",
            "Epoch 33/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.8770 - val_loss: 0.5645 - val_accuracy: 0.8741\n",
            "Epoch 34/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8824 - val_loss: 0.5786 - val_accuracy: 0.8811\n",
            "Epoch 35/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8824 - val_loss: 0.6637 - val_accuracy: 0.8601\n",
            "Epoch 36/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8837 - val_loss: 0.5145 - val_accuracy: 0.8531\n",
            "Epoch 37/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8944 - val_loss: 0.6142 - val_accuracy: 0.8671\n",
            "Epoch 38/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8890 - val_loss: 0.5600 - val_accuracy: 0.8741\n",
            "Epoch 39/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8904 - val_loss: 0.6827 - val_accuracy: 0.8531\n",
            "Epoch 40/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8864 - val_loss: 0.7177 - val_accuracy: 0.8601\n",
            "Epoch 41/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8944 - val_loss: 0.9281 - val_accuracy: 0.8392\n",
            "Epoch 42/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2570 - accuracy: 0.8904 - val_loss: 1.0994 - val_accuracy: 0.8462\n",
            "Epoch 43/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8864 - val_loss: 0.7038 - val_accuracy: 0.8601\n",
            "Epoch 44/1000\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.2552 - accuracy: 0.8917 - val_loss: 0.7167 - val_accuracy: 0.8462\n",
            "Epoch 45/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.8997 - val_loss: 0.9307 - val_accuracy: 0.8392\n",
            "Epoch 46/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8944 - val_loss: 0.9318 - val_accuracy: 0.8392\n",
            "Epoch 47/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.8890 - val_loss: 1.0003 - val_accuracy: 0.8322\n",
            "Epoch 48/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8864 - val_loss: 0.8532 - val_accuracy: 0.8462\n",
            "Epoch 49/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8984 - val_loss: 0.8982 - val_accuracy: 0.8462\n",
            "Epoch 50/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.8877 - val_loss: 0.8407 - val_accuracy: 0.8531\n",
            "Epoch 51/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.9011 - val_loss: 0.8131 - val_accuracy: 0.8392\n",
            "Epoch 52/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8944 - val_loss: 0.8481 - val_accuracy: 0.8531\n",
            "Epoch 53/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8944 - val_loss: 0.8959 - val_accuracy: 0.8531\n",
            "Epoch 54/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8890 - val_loss: 0.9502 - val_accuracy: 0.8462\n",
            "Epoch 55/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.8957 - val_loss: 1.1206 - val_accuracy: 0.8462\n",
            "Epoch 56/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2419 - accuracy: 0.8984 - val_loss: 1.0261 - val_accuracy: 0.8462\n",
            "Epoch 57/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2436 - accuracy: 0.8971 - val_loss: 0.8478 - val_accuracy: 0.8601\n",
            "Epoch 58/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8917 - val_loss: 1.1329 - val_accuracy: 0.8392\n",
            "Epoch 59/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.8971 - val_loss: 0.9247 - val_accuracy: 0.8462\n",
            "Epoch 60/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9011 - val_loss: 1.2186 - val_accuracy: 0.8392\n",
            "Epoch 61/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8997 - val_loss: 1.2644 - val_accuracy: 0.8112\n",
            "Epoch 62/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.8930 - val_loss: 1.2885 - val_accuracy: 0.8322\n",
            "Epoch 63/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.9024 - val_loss: 1.1299 - val_accuracy: 0.8462\n",
            "Epoch 64/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.9024 - val_loss: 1.1678 - val_accuracy: 0.8322\n",
            "Epoch 65/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.8997 - val_loss: 1.2319 - val_accuracy: 0.8392\n",
            "Epoch 66/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8904 - val_loss: 0.9736 - val_accuracy: 0.8392\n",
            "Epoch 67/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9078 - val_loss: 1.4091 - val_accuracy: 0.8531\n",
            "Epoch 68/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9064 - val_loss: 1.1245 - val_accuracy: 0.8392\n",
            "Epoch 69/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9011 - val_loss: 1.1888 - val_accuracy: 0.8462\n",
            "Epoch 70/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.9064 - val_loss: 1.1289 - val_accuracy: 0.8322\n",
            "Epoch 71/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8850 - val_loss: 1.1451 - val_accuracy: 0.8322\n",
            "Epoch 72/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9011 - val_loss: 1.4243 - val_accuracy: 0.8462\n",
            "Epoch 73/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8917 - val_loss: 1.1043 - val_accuracy: 0.8531\n",
            "Epoch 74/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9064 - val_loss: 1.5085 - val_accuracy: 0.8392\n",
            "Epoch 75/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8971 - val_loss: 0.9425 - val_accuracy: 0.8601\n",
            "Epoch 76/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2208 - accuracy: 0.9078 - val_loss: 1.1782 - val_accuracy: 0.8601\n",
            "Epoch 77/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9024 - val_loss: 1.0726 - val_accuracy: 0.8392\n",
            "Epoch 78/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2261 - accuracy: 0.9037 - val_loss: 1.0661 - val_accuracy: 0.8601\n",
            "Epoch 79/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9011 - val_loss: 1.1671 - val_accuracy: 0.8392\n",
            "Epoch 80/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9024 - val_loss: 1.1089 - val_accuracy: 0.8531\n",
            "Epoch 81/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9064 - val_loss: 1.4435 - val_accuracy: 0.8392\n",
            "Epoch 82/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8984 - val_loss: 1.3239 - val_accuracy: 0.8531\n",
            "Epoch 83/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.9024 - val_loss: 1.0412 - val_accuracy: 0.8601\n",
            "Epoch 84/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9051 - val_loss: 1.1123 - val_accuracy: 0.8531\n",
            "Epoch 85/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9078 - val_loss: 1.1699 - val_accuracy: 0.8531\n",
            "Epoch 86/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9158 - val_loss: 1.2807 - val_accuracy: 0.8601\n",
            "Epoch 87/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2436 - accuracy: 0.8984 - val_loss: 1.1989 - val_accuracy: 0.8531\n",
            "Epoch 88/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9064 - val_loss: 1.4633 - val_accuracy: 0.8462\n",
            "Epoch 89/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9064 - val_loss: 1.2230 - val_accuracy: 0.8392\n",
            "Epoch 90/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9078 - val_loss: 1.5423 - val_accuracy: 0.8531\n",
            "Epoch 91/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9011 - val_loss: 1.6980 - val_accuracy: 0.8392\n",
            "Epoch 92/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.9037 - val_loss: 1.0156 - val_accuracy: 0.8601\n",
            "Epoch 93/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9091 - val_loss: 1.2181 - val_accuracy: 0.8462\n",
            "Epoch 94/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.9064 - val_loss: 1.5673 - val_accuracy: 0.8601\n",
            "Epoch 95/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9024 - val_loss: 1.1675 - val_accuracy: 0.8531\n",
            "Epoch 96/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.8984 - val_loss: 1.5718 - val_accuracy: 0.8462\n",
            "Epoch 97/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9091 - val_loss: 1.2329 - val_accuracy: 0.8531\n",
            "Epoch 98/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9091 - val_loss: 1.6584 - val_accuracy: 0.8392\n",
            "Epoch 99/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9118 - val_loss: 1.7879 - val_accuracy: 0.8252\n",
            "Epoch 100/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9037 - val_loss: 1.2916 - val_accuracy: 0.8462\n",
            "Epoch 101/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.9011 - val_loss: 1.4462 - val_accuracy: 0.8462\n",
            "Epoch 102/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9118 - val_loss: 1.5669 - val_accuracy: 0.8601\n",
            "Epoch 103/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9104 - val_loss: 1.4946 - val_accuracy: 0.8462\n",
            "Epoch 104/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9171 - val_loss: 1.7916 - val_accuracy: 0.8392\n",
            "Epoch 105/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9091 - val_loss: 1.9438 - val_accuracy: 0.8322\n",
            "Epoch 106/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.9011 - val_loss: 1.4161 - val_accuracy: 0.8601\n",
            "Epoch 107/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.9118 - val_loss: 1.4453 - val_accuracy: 0.8392\n",
            "Epoch 108/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9118 - val_loss: 1.3371 - val_accuracy: 0.8462\n",
            "Epoch 109/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9118 - val_loss: 1.5756 - val_accuracy: 0.8392\n",
            "Epoch 110/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9144 - val_loss: 1.6037 - val_accuracy: 0.8531\n",
            "Epoch 111/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9144 - val_loss: 1.3863 - val_accuracy: 0.8531\n",
            "Epoch 112/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2286 - accuracy: 0.9078 - val_loss: 1.1279 - val_accuracy: 0.8531\n",
            "Epoch 113/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2087 - accuracy: 0.9144 - val_loss: 2.1943 - val_accuracy: 0.8182\n",
            "Epoch 114/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9037 - val_loss: 1.6940 - val_accuracy: 0.8392\n",
            "Epoch 115/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 0.9171 - val_loss: 1.5085 - val_accuracy: 0.8671\n",
            "Epoch 116/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9104 - val_loss: 1.6376 - val_accuracy: 0.8462\n",
            "Epoch 117/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9118 - val_loss: 1.5437 - val_accuracy: 0.8531\n",
            "Epoch 118/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9131 - val_loss: 1.8578 - val_accuracy: 0.8462\n",
            "Epoch 119/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9078 - val_loss: 1.6188 - val_accuracy: 0.8531\n",
            "Epoch 120/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.9011 - val_loss: 0.9942 - val_accuracy: 0.8392\n",
            "Epoch 121/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9171 - val_loss: 1.1007 - val_accuracy: 0.8601\n",
            "Epoch 122/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9131 - val_loss: 1.2132 - val_accuracy: 0.8392\n",
            "Epoch 123/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9064 - val_loss: 1.1144 - val_accuracy: 0.8531\n",
            "Epoch 124/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.9131 - val_loss: 1.3789 - val_accuracy: 0.8671\n",
            "Epoch 125/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9118 - val_loss: 1.3411 - val_accuracy: 0.8531\n",
            "Epoch 126/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.9078 - val_loss: 1.2984 - val_accuracy: 0.8531\n",
            "Epoch 127/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9184 - val_loss: 1.3337 - val_accuracy: 0.8392\n",
            "Epoch 128/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9091 - val_loss: 1.6406 - val_accuracy: 0.8322\n",
            "Epoch 129/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9064 - val_loss: 1.7168 - val_accuracy: 0.8531\n",
            "Epoch 130/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9104 - val_loss: 1.4833 - val_accuracy: 0.8601\n",
            "Epoch 131/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9131 - val_loss: 1.4068 - val_accuracy: 0.8601\n",
            "Epoch 132/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9158 - val_loss: 1.4533 - val_accuracy: 0.8531\n",
            "Epoch 133/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9144 - val_loss: 1.4876 - val_accuracy: 0.8531\n",
            "Epoch 134/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9064 - val_loss: 1.7027 - val_accuracy: 0.8392\n",
            "Epoch 135/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9144 - val_loss: 1.8395 - val_accuracy: 0.8322\n",
            "Epoch 136/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.9091 - val_loss: 1.4110 - val_accuracy: 0.8531\n",
            "Epoch 137/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9171 - val_loss: 1.4305 - val_accuracy: 0.8601\n",
            "Epoch 138/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9131 - val_loss: 1.6052 - val_accuracy: 0.8462\n",
            "Epoch 139/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9211 - val_loss: 1.5225 - val_accuracy: 0.8462\n",
            "Epoch 140/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9104 - val_loss: 1.5000 - val_accuracy: 0.8392\n",
            "Epoch 141/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9091 - val_loss: 1.6805 - val_accuracy: 0.8531\n",
            "Epoch 142/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9118 - val_loss: 1.8652 - val_accuracy: 0.8392\n",
            "Epoch 143/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9198 - val_loss: 1.8663 - val_accuracy: 0.8462\n",
            "Epoch 144/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9118 - val_loss: 2.0358 - val_accuracy: 0.8462\n",
            "Epoch 145/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9131 - val_loss: 2.4810 - val_accuracy: 0.8531\n",
            "Epoch 146/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.9091 - val_loss: 1.6682 - val_accuracy: 0.8462\n",
            "Epoch 147/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.9104 - val_loss: 1.4716 - val_accuracy: 0.8322\n",
            "Epoch 148/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2248 - accuracy: 0.9158 - val_loss: 1.4569 - val_accuracy: 0.8601\n",
            "Epoch 149/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1919 - accuracy: 0.9184 - val_loss: 2.0524 - val_accuracy: 0.8462\n",
            "Epoch 150/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9158 - val_loss: 1.5328 - val_accuracy: 0.8392\n",
            "Epoch 151/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9171 - val_loss: 2.2166 - val_accuracy: 0.8462\n",
            "Epoch 152/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9091 - val_loss: 1.6668 - val_accuracy: 0.8741\n",
            "Epoch 153/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.9091 - val_loss: 1.8373 - val_accuracy: 0.8741\n",
            "Epoch 154/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2001 - accuracy: 0.9144 - val_loss: 1.8815 - val_accuracy: 0.8531\n",
            "Epoch 155/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9184 - val_loss: 2.2783 - val_accuracy: 0.8531\n",
            "Epoch 156/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9104 - val_loss: 2.1614 - val_accuracy: 0.8392\n",
            "Epoch 157/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9144 - val_loss: 1.6866 - val_accuracy: 0.8462\n",
            "Epoch 158/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9171 - val_loss: 2.0852 - val_accuracy: 0.8531\n",
            "Epoch 159/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.9104 - val_loss: 1.9277 - val_accuracy: 0.8392\n",
            "Epoch 160/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9091 - val_loss: 2.0010 - val_accuracy: 0.8322\n",
            "Epoch 161/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.9198 - val_loss: 2.5690 - val_accuracy: 0.8392\n",
            "Epoch 162/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9184 - val_loss: 2.3590 - val_accuracy: 0.8252\n",
            "Epoch 163/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9171 - val_loss: 2.3897 - val_accuracy: 0.8392\n",
            "Epoch 164/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9144 - val_loss: 2.2374 - val_accuracy: 0.8182\n",
            "Epoch 165/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9131 - val_loss: 2.3701 - val_accuracy: 0.8462\n",
            "Epoch 166/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9171 - val_loss: 2.6440 - val_accuracy: 0.8252\n",
            "Epoch 167/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9144 - val_loss: 2.9096 - val_accuracy: 0.8112\n",
            "Epoch 168/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.9104 - val_loss: 1.5629 - val_accuracy: 0.8392\n",
            "Epoch 169/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9144 - val_loss: 1.4387 - val_accuracy: 0.8392\n",
            "Epoch 170/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.9184 - val_loss: 1.5292 - val_accuracy: 0.8531\n",
            "Epoch 171/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9211 - val_loss: 1.3865 - val_accuracy: 0.8601\n",
            "Epoch 172/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9211 - val_loss: 1.6257 - val_accuracy: 0.8462\n",
            "Epoch 173/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9144 - val_loss: 1.8099 - val_accuracy: 0.8322\n",
            "Epoch 174/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2038 - accuracy: 0.9131 - val_loss: 2.1374 - val_accuracy: 0.8392\n",
            "Epoch 175/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.9064 - val_loss: 1.6006 - val_accuracy: 0.8601\n",
            "Epoch 176/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 1.7030 - val_accuracy: 0.8392\n",
            "Epoch 177/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9171 - val_loss: 1.9259 - val_accuracy: 0.8392\n",
            "Epoch 178/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9225 - val_loss: 1.9359 - val_accuracy: 0.8252\n",
            "Epoch 179/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9118 - val_loss: 1.9388 - val_accuracy: 0.8042\n",
            "Epoch 180/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9171 - val_loss: 2.2085 - val_accuracy: 0.8182\n",
            "Epoch 181/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1969 - accuracy: 0.9158 - val_loss: 2.3143 - val_accuracy: 0.8322\n",
            "Epoch 182/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.9011 - val_loss: 1.6435 - val_accuracy: 0.8392\n",
            "Epoch 183/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9211 - val_loss: 1.8007 - val_accuracy: 0.8392\n",
            "Epoch 184/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9211 - val_loss: 1.8195 - val_accuracy: 0.8392\n",
            "Epoch 185/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9238 - val_loss: 1.8910 - val_accuracy: 0.8462\n",
            "Epoch 186/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.9144 - val_loss: 2.0829 - val_accuracy: 0.8462\n",
            "Epoch 187/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.9131 - val_loss: 1.9076 - val_accuracy: 0.8462\n",
            "Epoch 188/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9184 - val_loss: 1.9357 - val_accuracy: 0.8182\n",
            "Epoch 189/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9158 - val_loss: 1.7447 - val_accuracy: 0.8531\n",
            "Epoch 190/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9184 - val_loss: 2.2982 - val_accuracy: 0.8322\n",
            "Epoch 191/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9171 - val_loss: 2.4281 - val_accuracy: 0.8322\n",
            "Epoch 192/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9184 - val_loss: 3.0377 - val_accuracy: 0.8182\n",
            "Epoch 193/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9211 - val_loss: 2.4577 - val_accuracy: 0.8252\n",
            "Epoch 194/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9131 - val_loss: 1.7842 - val_accuracy: 0.8322\n",
            "Epoch 195/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9158 - val_loss: 1.7584 - val_accuracy: 0.8392\n",
            "Epoch 196/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9211 - val_loss: 1.9508 - val_accuracy: 0.8392\n",
            "Epoch 197/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9171 - val_loss: 2.0127 - val_accuracy: 0.8462\n",
            "Epoch 198/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.9158 - val_loss: 1.8239 - val_accuracy: 0.8392\n",
            "Epoch 199/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9184 - val_loss: 2.4078 - val_accuracy: 0.8392\n",
            "Epoch 200/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1871 - accuracy: 0.9225 - val_loss: 2.2176 - val_accuracy: 0.8462\n",
            "Epoch 201/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9144 - val_loss: 2.4596 - val_accuracy: 0.8392\n",
            "Epoch 202/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9225 - val_loss: 3.1026 - val_accuracy: 0.8322\n",
            "Epoch 203/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.9144 - val_loss: 2.0242 - val_accuracy: 0.8462\n",
            "Epoch 204/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9225 - val_loss: 2.2509 - val_accuracy: 0.8392\n",
            "Epoch 205/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1924 - accuracy: 0.9171 - val_loss: 1.8909 - val_accuracy: 0.8182\n",
            "Epoch 206/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9211 - val_loss: 2.6412 - val_accuracy: 0.8392\n",
            "Epoch 207/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9184 - val_loss: 2.6552 - val_accuracy: 0.8322\n",
            "Epoch 208/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9211 - val_loss: 2.2778 - val_accuracy: 0.8392\n",
            "Epoch 209/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 2.4918 - val_accuracy: 0.8252\n",
            "Epoch 210/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.9184 - val_loss: 2.5869 - val_accuracy: 0.8322\n",
            "Epoch 211/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.9131 - val_loss: 2.1204 - val_accuracy: 0.8462\n",
            "Epoch 212/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9238 - val_loss: 2.5944 - val_accuracy: 0.8392\n",
            "Epoch 213/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9198 - val_loss: 2.8370 - val_accuracy: 0.8462\n",
            "Epoch 214/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9238 - val_loss: 3.2211 - val_accuracy: 0.8322\n",
            "Epoch 215/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9158 - val_loss: 3.2862 - val_accuracy: 0.8462\n",
            "Epoch 216/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9225 - val_loss: 3.3571 - val_accuracy: 0.8252\n",
            "Epoch 217/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.9118 - val_loss: 3.2047 - val_accuracy: 0.8531\n",
            "Epoch 218/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.9171 - val_loss: 2.2855 - val_accuracy: 0.8392\n",
            "Epoch 219/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.9184 - val_loss: 2.6213 - val_accuracy: 0.8531\n",
            "Epoch 220/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9265 - val_loss: 2.7893 - val_accuracy: 0.8322\n",
            "Epoch 221/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9251 - val_loss: 3.1809 - val_accuracy: 0.8252\n",
            "Epoch 222/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9211 - val_loss: 2.1759 - val_accuracy: 0.8252\n",
            "Epoch 223/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9225 - val_loss: 2.8781 - val_accuracy: 0.8322\n",
            "Epoch 224/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9198 - val_loss: 2.6735 - val_accuracy: 0.8322\n",
            "Epoch 225/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9225 - val_loss: 1.9950 - val_accuracy: 0.8252\n",
            "Epoch 226/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9238 - val_loss: 3.2952 - val_accuracy: 0.8182\n",
            "Epoch 227/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9238 - val_loss: 2.8871 - val_accuracy: 0.8322\n",
            "Epoch 228/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9144 - val_loss: 2.7209 - val_accuracy: 0.8531\n",
            "Epoch 229/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1929 - accuracy: 0.9251 - val_loss: 2.7571 - val_accuracy: 0.8392\n",
            "Epoch 230/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9211 - val_loss: 2.7615 - val_accuracy: 0.8462\n",
            "Epoch 231/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9198 - val_loss: 3.2086 - val_accuracy: 0.8322\n",
            "Epoch 232/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9198 - val_loss: 3.2703 - val_accuracy: 0.8252\n",
            "Epoch 233/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 3.6359 - val_accuracy: 0.8322\n",
            "Epoch 234/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9171 - val_loss: 3.2106 - val_accuracy: 0.8252\n",
            "Epoch 235/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9238 - val_loss: 4.4064 - val_accuracy: 0.8462\n",
            "Epoch 236/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9211 - val_loss: 4.7883 - val_accuracy: 0.8322\n",
            "Epoch 237/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.9144 - val_loss: 4.0393 - val_accuracy: 0.8462\n",
            "Epoch 238/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9278 - val_loss: 4.6843 - val_accuracy: 0.8392\n",
            "Epoch 239/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9158 - val_loss: 3.7321 - val_accuracy: 0.8182\n",
            "Epoch 240/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.9251 - val_loss: 4.6724 - val_accuracy: 0.8112\n",
            "Epoch 241/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2372 - accuracy: 0.9238 - val_loss: 3.9075 - val_accuracy: 0.8112\n",
            "Epoch 242/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9198 - val_loss: 3.5640 - val_accuracy: 0.8042\n",
            "Epoch 243/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9225 - val_loss: 3.6273 - val_accuracy: 0.8112\n",
            "Epoch 244/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9184 - val_loss: 2.8235 - val_accuracy: 0.8462\n",
            "Epoch 245/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9171 - val_loss: 2.9018 - val_accuracy: 0.8392\n",
            "Epoch 246/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.9238 - val_loss: 3.2162 - val_accuracy: 0.8462\n",
            "Epoch 247/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9171 - val_loss: 2.8406 - val_accuracy: 0.8182\n",
            "Epoch 248/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9184 - val_loss: 3.7028 - val_accuracy: 0.8252\n",
            "Epoch 249/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9118 - val_loss: 2.7519 - val_accuracy: 0.8392\n",
            "Epoch 250/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9265 - val_loss: 2.9052 - val_accuracy: 0.8392\n",
            "Epoch 251/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9251 - val_loss: 3.3926 - val_accuracy: 0.8392\n",
            "Epoch 252/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9265 - val_loss: 3.1875 - val_accuracy: 0.8182\n",
            "Epoch 253/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9198 - val_loss: 2.9856 - val_accuracy: 0.8252\n",
            "Epoch 254/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9251 - val_loss: 3.6057 - val_accuracy: 0.8252\n",
            "Epoch 255/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9184 - val_loss: 3.0540 - val_accuracy: 0.7972\n",
            "Epoch 256/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9184 - val_loss: 2.3777 - val_accuracy: 0.8322\n",
            "Epoch 257/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9305 - val_loss: 2.6832 - val_accuracy: 0.8112\n",
            "Epoch 258/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9198 - val_loss: 2.7724 - val_accuracy: 0.8462\n",
            "Epoch 259/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9158 - val_loss: 3.5361 - val_accuracy: 0.8112\n",
            "Epoch 260/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9238 - val_loss: 3.5427 - val_accuracy: 0.8252\n",
            "Epoch 261/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9251 - val_loss: 3.5539 - val_accuracy: 0.8322\n",
            "Epoch 262/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9211 - val_loss: 3.4165 - val_accuracy: 0.8322\n",
            "Epoch 263/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9238 - val_loss: 3.9038 - val_accuracy: 0.8112\n",
            "Epoch 264/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9171 - val_loss: 3.2269 - val_accuracy: 0.8182\n",
            "Epoch 265/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9238 - val_loss: 4.0847 - val_accuracy: 0.8252\n",
            "Epoch 266/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2225 - accuracy: 0.9118 - val_loss: 4.2507 - val_accuracy: 0.8182\n",
            "Epoch 267/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.9238 - val_loss: 3.7906 - val_accuracy: 0.8462\n",
            "Epoch 268/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.9211 - val_loss: 2.9096 - val_accuracy: 0.8322\n",
            "Epoch 269/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9305 - val_loss: 3.2472 - val_accuracy: 0.8252\n",
            "Epoch 270/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9198 - val_loss: 2.5425 - val_accuracy: 0.8462\n",
            "Epoch 271/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9211 - val_loss: 3.9680 - val_accuracy: 0.8182\n",
            "Epoch 272/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9171 - val_loss: 2.7034 - val_accuracy: 0.8182\n",
            "Epoch 273/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2244 - accuracy: 0.9238 - val_loss: 2.9426 - val_accuracy: 0.8182\n",
            "Epoch 274/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9225 - val_loss: 2.3740 - val_accuracy: 0.8392\n",
            "Epoch 275/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9278 - val_loss: 2.5027 - val_accuracy: 0.8182\n",
            "Epoch 276/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9225 - val_loss: 2.6071 - val_accuracy: 0.8322\n",
            "Epoch 277/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9251 - val_loss: 2.7998 - val_accuracy: 0.8252\n",
            "Epoch 278/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9251 - val_loss: 4.3001 - val_accuracy: 0.8182\n",
            "Epoch 279/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9211 - val_loss: 4.0245 - val_accuracy: 0.8182\n",
            "Epoch 280/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.9104 - val_loss: 2.0662 - val_accuracy: 0.8182\n",
            "Epoch 281/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9305 - val_loss: 2.7033 - val_accuracy: 0.8182\n",
            "Epoch 282/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9251 - val_loss: 2.6506 - val_accuracy: 0.8182\n",
            "Epoch 283/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1896 - accuracy: 0.9171 - val_loss: 2.4771 - val_accuracy: 0.8252\n",
            "Epoch 284/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9171 - val_loss: 3.0695 - val_accuracy: 0.8182\n",
            "Epoch 285/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9251 - val_loss: 3.1916 - val_accuracy: 0.8182\n",
            "Epoch 286/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9211 - val_loss: 3.1742 - val_accuracy: 0.8252\n",
            "Epoch 287/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.9184 - val_loss: 3.3653 - val_accuracy: 0.8252\n",
            "Epoch 288/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9225 - val_loss: 3.9481 - val_accuracy: 0.8182\n",
            "Epoch 289/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.9144 - val_loss: 3.5163 - val_accuracy: 0.7972\n",
            "Epoch 290/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9251 - val_loss: 3.7181 - val_accuracy: 0.8182\n",
            "Epoch 291/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9251 - val_loss: 4.0763 - val_accuracy: 0.8252\n",
            "Epoch 292/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9225 - val_loss: 4.3294 - val_accuracy: 0.8252\n",
            "Epoch 293/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9198 - val_loss: 3.8168 - val_accuracy: 0.8252\n",
            "Epoch 294/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9225 - val_loss: 3.6541 - val_accuracy: 0.8322\n",
            "Epoch 295/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9171 - val_loss: 3.9369 - val_accuracy: 0.8252\n",
            "Epoch 296/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.9251 - val_loss: 3.1768 - val_accuracy: 0.8392\n",
            "Epoch 297/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9265 - val_loss: 3.0361 - val_accuracy: 0.8462\n",
            "Epoch 298/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9278 - val_loss: 3.7040 - val_accuracy: 0.8322\n",
            "Epoch 299/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9225 - val_loss: 3.5666 - val_accuracy: 0.8182\n",
            "Epoch 300/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9251 - val_loss: 3.5277 - val_accuracy: 0.8462\n",
            "Epoch 301/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9225 - val_loss: 3.4330 - val_accuracy: 0.8462\n",
            "Epoch 302/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 3.8280 - val_accuracy: 0.8112\n",
            "Epoch 303/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.9225 - val_loss: 2.7311 - val_accuracy: 0.8252\n",
            "Epoch 304/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9251 - val_loss: 2.2543 - val_accuracy: 0.8182\n",
            "Epoch 305/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9265 - val_loss: 2.2858 - val_accuracy: 0.8252\n",
            "Epoch 306/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9278 - val_loss: 3.0433 - val_accuracy: 0.8252\n",
            "Epoch 307/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.9158 - val_loss: 2.6103 - val_accuracy: 0.8252\n",
            "Epoch 308/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9225 - val_loss: 2.7576 - val_accuracy: 0.8182\n",
            "Epoch 309/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 2.8024 - val_accuracy: 0.8322\n",
            "Epoch 310/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 0.9238 - val_loss: 2.8310 - val_accuracy: 0.8322\n",
            "Epoch 311/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9238 - val_loss: 4.0331 - val_accuracy: 0.8182\n",
            "Epoch 312/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9278 - val_loss: 3.4763 - val_accuracy: 0.8042\n",
            "Epoch 313/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9225 - val_loss: 3.5314 - val_accuracy: 0.8112\n",
            "Epoch 314/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9278 - val_loss: 3.0245 - val_accuracy: 0.8322\n",
            "Epoch 315/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9225 - val_loss: 3.3563 - val_accuracy: 0.8182\n",
            "Epoch 316/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9225 - val_loss: 3.9687 - val_accuracy: 0.8182\n",
            "Epoch 317/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9198 - val_loss: 4.6436 - val_accuracy: 0.8462\n",
            "Epoch 318/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9184 - val_loss: 4.3846 - val_accuracy: 0.8182\n",
            "Epoch 319/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9211 - val_loss: 4.5390 - val_accuracy: 0.8042\n",
            "Epoch 320/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9265 - val_loss: 4.5632 - val_accuracy: 0.8252\n",
            "Epoch 321/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2051 - accuracy: 0.9238 - val_loss: 4.7955 - val_accuracy: 0.8182\n",
            "Epoch 322/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9225 - val_loss: 4.9156 - val_accuracy: 0.8182\n",
            "Epoch 323/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9211 - val_loss: 4.8318 - val_accuracy: 0.8252\n",
            "Epoch 324/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9225 - val_loss: 5.6103 - val_accuracy: 0.8322\n",
            "Epoch 325/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9198 - val_loss: 5.5105 - val_accuracy: 0.8322\n",
            "Epoch 326/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2548 - accuracy: 0.9238 - val_loss: 4.4458 - val_accuracy: 0.8042\n",
            "Epoch 327/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9184 - val_loss: 9.3232 - val_accuracy: 0.8042\n",
            "Epoch 328/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.9251 - val_loss: 3.6963 - val_accuracy: 0.8322\n",
            "Epoch 329/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9291 - val_loss: 3.7960 - val_accuracy: 0.8322\n",
            "Epoch 330/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9251 - val_loss: 3.4071 - val_accuracy: 0.8322\n",
            "Epoch 331/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9225 - val_loss: 3.4104 - val_accuracy: 0.8322\n",
            "Epoch 332/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.9238 - val_loss: 5.8544 - val_accuracy: 0.8042\n",
            "Epoch 333/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 0.9225 - val_loss: 4.3984 - val_accuracy: 0.8252\n",
            "Epoch 334/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9291 - val_loss: 5.1853 - val_accuracy: 0.8042\n",
            "Epoch 335/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2038 - accuracy: 0.9251 - val_loss: 5.0722 - val_accuracy: 0.8322\n",
            "Epoch 336/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9265 - val_loss: 4.6565 - val_accuracy: 0.8252\n",
            "Epoch 337/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9265 - val_loss: 5.0871 - val_accuracy: 0.8252\n",
            "Epoch 338/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 5.3442 - val_accuracy: 0.8322\n",
            "Epoch 339/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9265 - val_loss: 5.5359 - val_accuracy: 0.8322\n",
            "Epoch 340/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.9225 - val_loss: 9.3696 - val_accuracy: 0.7762\n",
            "Epoch 341/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.9144 - val_loss: 4.0346 - val_accuracy: 0.8182\n",
            "Epoch 342/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9291 - val_loss: 4.2905 - val_accuracy: 0.8182\n",
            "Epoch 343/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 4.2888 - val_accuracy: 0.8042\n",
            "Epoch 344/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9251 - val_loss: 4.3471 - val_accuracy: 0.8252\n",
            "Epoch 345/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9225 - val_loss: 4.1890 - val_accuracy: 0.8042\n",
            "Epoch 346/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9238 - val_loss: 4.7339 - val_accuracy: 0.8322\n",
            "Epoch 347/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.9238 - val_loss: 4.6942 - val_accuracy: 0.8182\n",
            "Epoch 348/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1719 - accuracy: 0.9278 - val_loss: 5.2689 - val_accuracy: 0.8392\n",
            "Epoch 349/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9225 - val_loss: 4.8135 - val_accuracy: 0.8322\n",
            "Epoch 350/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.9158 - val_loss: 4.2605 - val_accuracy: 0.8252\n",
            "Epoch 351/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9278 - val_loss: 3.6598 - val_accuracy: 0.8182\n",
            "Epoch 352/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 4.3900 - val_accuracy: 0.8252\n",
            "Epoch 353/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9198 - val_loss: 4.1531 - val_accuracy: 0.8112\n",
            "Epoch 354/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9278 - val_loss: 4.8022 - val_accuracy: 0.8322\n",
            "Epoch 355/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9265 - val_loss: 5.7957 - val_accuracy: 0.8182\n",
            "Epoch 356/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9158 - val_loss: 3.1593 - val_accuracy: 0.8322\n",
            "Epoch 357/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9238 - val_loss: 3.3070 - val_accuracy: 0.8182\n",
            "Epoch 358/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9251 - val_loss: 3.3705 - val_accuracy: 0.8182\n",
            "Epoch 359/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9251 - val_loss: 4.3771 - val_accuracy: 0.8322\n",
            "Epoch 360/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9198 - val_loss: 3.8465 - val_accuracy: 0.8252\n",
            "Epoch 361/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9278 - val_loss: 4.1230 - val_accuracy: 0.8322\n",
            "Epoch 362/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.9211 - val_loss: 8.7469 - val_accuracy: 0.8392\n",
            "Epoch 363/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.9118 - val_loss: 4.4686 - val_accuracy: 0.8392\n",
            "Epoch 364/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9278 - val_loss: 4.7421 - val_accuracy: 0.8392\n",
            "Epoch 365/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9318 - val_loss: 4.1564 - val_accuracy: 0.8322\n",
            "Epoch 366/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9184 - val_loss: 3.5938 - val_accuracy: 0.8042\n",
            "Epoch 367/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9171 - val_loss: 2.2147 - val_accuracy: 0.8112\n",
            "Epoch 368/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9251 - val_loss: 3.3140 - val_accuracy: 0.8322\n",
            "Epoch 369/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9251 - val_loss: 3.2839 - val_accuracy: 0.8112\n",
            "Epoch 370/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9278 - val_loss: 3.8178 - val_accuracy: 0.8182\n",
            "Epoch 371/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9238 - val_loss: 4.0143 - val_accuracy: 0.8392\n",
            "Epoch 372/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9225 - val_loss: 4.4983 - val_accuracy: 0.7972\n",
            "Epoch 373/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9211 - val_loss: 3.6294 - val_accuracy: 0.8042\n",
            "Epoch 374/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9278 - val_loss: 4.0815 - val_accuracy: 0.8462\n",
            "Epoch 375/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9211 - val_loss: 5.3143 - val_accuracy: 0.8112\n",
            "Epoch 376/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9251 - val_loss: 5.2702 - val_accuracy: 0.8252\n",
            "Epoch 377/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9265 - val_loss: 4.9638 - val_accuracy: 0.8182\n",
            "Epoch 378/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9278 - val_loss: 5.7482 - val_accuracy: 0.8112\n",
            "Epoch 379/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9291 - val_loss: 5.9339 - val_accuracy: 0.8252\n",
            "Epoch 380/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.9104 - val_loss: 4.5461 - val_accuracy: 0.8042\n",
            "Epoch 381/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9251 - val_loss: 4.9701 - val_accuracy: 0.8322\n",
            "Epoch 382/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9291 - val_loss: 5.4939 - val_accuracy: 0.8252\n",
            "Epoch 383/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9265 - val_loss: 5.9957 - val_accuracy: 0.8042\n",
            "Epoch 384/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1822 - accuracy: 0.9238 - val_loss: 4.6701 - val_accuracy: 0.8252\n",
            "Epoch 385/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9238 - val_loss: 4.4591 - val_accuracy: 0.8252\n",
            "Epoch 386/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9251 - val_loss: 5.3120 - val_accuracy: 0.8112\n",
            "Epoch 387/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9251 - val_loss: 6.1883 - val_accuracy: 0.8182\n",
            "Epoch 388/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.9198 - val_loss: 6.3485 - val_accuracy: 0.8252\n",
            "Epoch 389/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9291 - val_loss: 6.3486 - val_accuracy: 0.8182\n",
            "Epoch 390/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9305 - val_loss: 7.1536 - val_accuracy: 0.8112\n",
            "Epoch 391/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9278 - val_loss: 6.2891 - val_accuracy: 0.8252\n",
            "Epoch 392/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9198 - val_loss: 5.3568 - val_accuracy: 0.8252\n",
            "Epoch 393/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9291 - val_loss: 5.5735 - val_accuracy: 0.8252\n",
            "Epoch 394/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9291 - val_loss: 5.6956 - val_accuracy: 0.8252\n",
            "Epoch 395/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9184 - val_loss: 5.0470 - val_accuracy: 0.8112\n",
            "Epoch 396/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2391 - accuracy: 0.9198 - val_loss: 4.4135 - val_accuracy: 0.8182\n",
            "Epoch 397/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9278 - val_loss: 6.4758 - val_accuracy: 0.8112\n",
            "Epoch 398/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9278 - val_loss: 5.4208 - val_accuracy: 0.8042\n",
            "Epoch 399/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9225 - val_loss: 5.4021 - val_accuracy: 0.8252\n",
            "Epoch 400/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9238 - val_loss: 5.2125 - val_accuracy: 0.8322\n",
            "Epoch 401/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9305 - val_loss: 5.8510 - val_accuracy: 0.8252\n",
            "Epoch 402/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.9238 - val_loss: 6.7621 - val_accuracy: 0.8182\n",
            "Epoch 403/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9171 - val_loss: 5.9010 - val_accuracy: 0.8322\n",
            "Epoch 404/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9278 - val_loss: 7.2448 - val_accuracy: 0.8252\n",
            "Epoch 405/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9211 - val_loss: 6.9461 - val_accuracy: 0.8392\n",
            "Epoch 406/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9278 - val_loss: 7.5161 - val_accuracy: 0.8182\n",
            "Epoch 407/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9198 - val_loss: 7.3695 - val_accuracy: 0.8112\n",
            "Epoch 408/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9251 - val_loss: 6.6337 - val_accuracy: 0.8252\n",
            "Epoch 409/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9318 - val_loss: 7.9105 - val_accuracy: 0.8392\n",
            "Epoch 410/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9291 - val_loss: 8.8515 - val_accuracy: 0.8042\n",
            "Epoch 411/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9184 - val_loss: 6.0147 - val_accuracy: 0.8182\n",
            "Epoch 412/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.9251 - val_loss: 4.7320 - val_accuracy: 0.8392\n",
            "Epoch 413/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9291 - val_loss: 5.1105 - val_accuracy: 0.8252\n",
            "Epoch 414/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9318 - val_loss: 5.4387 - val_accuracy: 0.8182\n",
            "Epoch 415/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9265 - val_loss: 5.6378 - val_accuracy: 0.8252\n",
            "Epoch 416/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9251 - val_loss: 5.5372 - val_accuracy: 0.8392\n",
            "Epoch 417/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9251 - val_loss: 6.6907 - val_accuracy: 0.8182\n",
            "Epoch 418/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9305 - val_loss: 5.7115 - val_accuracy: 0.8112\n",
            "Epoch 419/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1648 - accuracy: 0.9291 - val_loss: 6.0149 - val_accuracy: 0.8112\n",
            "Epoch 420/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9305 - val_loss: 6.1757 - val_accuracy: 0.8042\n",
            "Epoch 421/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9238 - val_loss: 5.8259 - val_accuracy: 0.8252\n",
            "Epoch 422/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.9251 - val_loss: 6.8122 - val_accuracy: 0.8042\n",
            "Epoch 423/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9265 - val_loss: 4.6455 - val_accuracy: 0.8112\n",
            "Epoch 424/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9251 - val_loss: 4.8734 - val_accuracy: 0.8182\n",
            "Epoch 425/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9305 - val_loss: 4.9140 - val_accuracy: 0.8112\n",
            "Epoch 426/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9251 - val_loss: 4.2013 - val_accuracy: 0.8322\n",
            "Epoch 427/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9265 - val_loss: 5.5310 - val_accuracy: 0.8112\n",
            "Epoch 428/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9291 - val_loss: 6.9978 - val_accuracy: 0.8322\n",
            "Epoch 429/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9251 - val_loss: 6.7975 - val_accuracy: 0.8252\n",
            "Epoch 430/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9225 - val_loss: 8.4646 - val_accuracy: 0.8112\n",
            "Epoch 431/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.9225 - val_loss: 8.0740 - val_accuracy: 0.8182\n",
            "Epoch 432/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9305 - val_loss: 11.5839 - val_accuracy: 0.8112\n",
            "Epoch 433/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.9211 - val_loss: 6.9609 - val_accuracy: 0.8392\n",
            "Epoch 434/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9291 - val_loss: 6.4316 - val_accuracy: 0.8392\n",
            "Epoch 435/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9291 - val_loss: 6.2099 - val_accuracy: 0.8182\n",
            "Epoch 436/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9305 - val_loss: 7.2084 - val_accuracy: 0.8322\n",
            "Epoch 437/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9278 - val_loss: 7.6673 - val_accuracy: 0.8252\n",
            "Epoch 438/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.9278 - val_loss: 7.8669 - val_accuracy: 0.8462\n",
            "Epoch 439/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9225 - val_loss: 7.7288 - val_accuracy: 0.8252\n",
            "Epoch 440/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9265 - val_loss: 7.9202 - val_accuracy: 0.8252\n",
            "Epoch 441/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9291 - val_loss: 7.6994 - val_accuracy: 0.8322\n",
            "Epoch 442/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9305 - val_loss: 7.7828 - val_accuracy: 0.8462\n",
            "Epoch 443/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9251 - val_loss: 9.1790 - val_accuracy: 0.8112\n",
            "Epoch 444/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9251 - val_loss: 7.5597 - val_accuracy: 0.8322\n",
            "Epoch 445/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9318 - val_loss: 8.0275 - val_accuracy: 0.8252\n",
            "Epoch 446/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.9225 - val_loss: 5.4608 - val_accuracy: 0.8462\n",
            "Epoch 447/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9305 - val_loss: 5.9652 - val_accuracy: 0.8182\n",
            "Epoch 448/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9318 - val_loss: 5.5398 - val_accuracy: 0.8392\n",
            "Epoch 449/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9211 - val_loss: 5.6289 - val_accuracy: 0.8322\n",
            "Epoch 450/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1685 - accuracy: 0.9291 - val_loss: 6.6804 - val_accuracy: 0.8112\n",
            "Epoch 451/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9332 - val_loss: 6.3665 - val_accuracy: 0.8252\n",
            "Epoch 452/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 5.0095 - val_accuracy: 0.8112\n",
            "Epoch 453/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9238 - val_loss: 5.4308 - val_accuracy: 0.8182\n",
            "Epoch 454/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9265 - val_loss: 6.6154 - val_accuracy: 0.8112\n",
            "Epoch 455/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.9131 - val_loss: 4.4020 - val_accuracy: 0.8182\n",
            "Epoch 456/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9332 - val_loss: 5.4748 - val_accuracy: 0.8112\n",
            "Epoch 457/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9345 - val_loss: 5.1417 - val_accuracy: 0.8182\n",
            "Epoch 458/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9225 - val_loss: 5.8911 - val_accuracy: 0.8182\n",
            "Epoch 459/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9225 - val_loss: 5.8552 - val_accuracy: 0.7902\n",
            "Epoch 460/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9265 - val_loss: 5.9591 - val_accuracy: 0.8182\n",
            "Epoch 461/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9291 - val_loss: 6.9036 - val_accuracy: 0.7972\n",
            "Epoch 462/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9251 - val_loss: 7.2597 - val_accuracy: 0.8182\n",
            "Epoch 463/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.9225 - val_loss: 4.9688 - val_accuracy: 0.8182\n",
            "Epoch 464/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.9225 - val_loss: 5.0848 - val_accuracy: 0.8182\n",
            "Epoch 465/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9358 - val_loss: 5.7117 - val_accuracy: 0.8112\n",
            "Epoch 466/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9278 - val_loss: 5.4270 - val_accuracy: 0.8182\n",
            "Epoch 467/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9251 - val_loss: 5.3095 - val_accuracy: 0.8322\n",
            "Epoch 468/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9278 - val_loss: 5.0871 - val_accuracy: 0.8112\n",
            "Epoch 469/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.9291 - val_loss: 6.2112 - val_accuracy: 0.8182\n",
            "Epoch 470/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9251 - val_loss: 7.0831 - val_accuracy: 0.8112\n",
            "Epoch 471/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9305 - val_loss: 8.2700 - val_accuracy: 0.8182\n",
            "Epoch 472/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9225 - val_loss: 7.7170 - val_accuracy: 0.8112\n",
            "Epoch 473/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9318 - val_loss: 8.4330 - val_accuracy: 0.8042\n",
            "Epoch 474/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9265 - val_loss: 8.4357 - val_accuracy: 0.8112\n",
            "Epoch 475/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9305 - val_loss: 8.2912 - val_accuracy: 0.8042\n",
            "Epoch 476/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9251 - val_loss: 7.5756 - val_accuracy: 0.7972\n",
            "Epoch 477/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9251 - val_loss: 7.3674 - val_accuracy: 0.8112\n",
            "Epoch 478/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9305 - val_loss: 7.1780 - val_accuracy: 0.8112\n",
            "Epoch 479/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9318 - val_loss: 8.4480 - val_accuracy: 0.8112\n",
            "Epoch 480/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9265 - val_loss: 8.6371 - val_accuracy: 0.8182\n",
            "Epoch 481/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9251 - val_loss: 8.0743 - val_accuracy: 0.8182\n",
            "Epoch 482/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.9238 - val_loss: 8.1173 - val_accuracy: 0.8182\n",
            "Epoch 483/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9265 - val_loss: 7.6053 - val_accuracy: 0.8322\n",
            "Epoch 484/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9291 - val_loss: 8.9341 - val_accuracy: 0.8322\n",
            "Epoch 485/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9318 - val_loss: 8.8634 - val_accuracy: 0.8252\n",
            "Epoch 486/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9291 - val_loss: 9.2283 - val_accuracy: 0.8322\n",
            "Epoch 487/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.9144 - val_loss: 4.8333 - val_accuracy: 0.8462\n",
            "Epoch 488/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9318 - val_loss: 5.1145 - val_accuracy: 0.8322\n",
            "Epoch 489/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9278 - val_loss: 5.5757 - val_accuracy: 0.8042\n",
            "Epoch 490/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9265 - val_loss: 5.3838 - val_accuracy: 0.7902\n",
            "Epoch 491/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9332 - val_loss: 6.6542 - val_accuracy: 0.7902\n",
            "Epoch 492/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9278 - val_loss: 6.6488 - val_accuracy: 0.8042\n",
            "Epoch 493/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9265 - val_loss: 5.2900 - val_accuracy: 0.8252\n",
            "Epoch 494/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.9225 - val_loss: 5.3802 - val_accuracy: 0.8182\n",
            "Epoch 495/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.9265 - val_loss: 4.4775 - val_accuracy: 0.8322\n",
            "Epoch 496/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9305 - val_loss: 4.7162 - val_accuracy: 0.8322\n",
            "Epoch 497/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9305 - val_loss: 4.8237 - val_accuracy: 0.8182\n",
            "Epoch 498/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9305 - val_loss: 5.0128 - val_accuracy: 0.8392\n",
            "Epoch 499/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9305 - val_loss: 6.0915 - val_accuracy: 0.8322\n",
            "Epoch 500/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9318 - val_loss: 7.3760 - val_accuracy: 0.8322\n",
            "Epoch 501/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9305 - val_loss: 9.3572 - val_accuracy: 0.8182\n",
            "Epoch 502/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.9238 - val_loss: 6.3339 - val_accuracy: 0.8252\n",
            "Epoch 503/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9265 - val_loss: 5.5261 - val_accuracy: 0.8182\n",
            "Epoch 504/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9291 - val_loss: 6.0014 - val_accuracy: 0.8392\n",
            "Epoch 505/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9291 - val_loss: 5.9043 - val_accuracy: 0.8182\n",
            "Epoch 506/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9305 - val_loss: 5.8457 - val_accuracy: 0.8182\n",
            "Epoch 507/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9318 - val_loss: 7.4509 - val_accuracy: 0.8182\n",
            "Epoch 508/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9318 - val_loss: 7.9500 - val_accuracy: 0.8182\n",
            "Epoch 509/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9278 - val_loss: 7.1046 - val_accuracy: 0.8182\n",
            "Epoch 510/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9305 - val_loss: 8.0498 - val_accuracy: 0.8252\n",
            "Epoch 511/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9291 - val_loss: 5.9264 - val_accuracy: 0.8392\n",
            "Epoch 512/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9265 - val_loss: 5.3509 - val_accuracy: 0.8252\n",
            "Epoch 513/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9278 - val_loss: 5.8577 - val_accuracy: 0.8462\n",
            "Epoch 514/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9278 - val_loss: 6.9207 - val_accuracy: 0.8112\n",
            "Epoch 515/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2059 - accuracy: 0.9278 - val_loss: 5.9657 - val_accuracy: 0.8392\n",
            "Epoch 516/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9278 - val_loss: 6.6015 - val_accuracy: 0.8392\n",
            "Epoch 517/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9291 - val_loss: 5.8586 - val_accuracy: 0.8462\n",
            "Epoch 518/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2008 - accuracy: 0.9265 - val_loss: 6.8653 - val_accuracy: 0.8322\n",
            "Epoch 519/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9305 - val_loss: 6.8486 - val_accuracy: 0.8322\n",
            "Epoch 520/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9318 - val_loss: 6.8337 - val_accuracy: 0.8252\n",
            "Epoch 521/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9305 - val_loss: 8.0992 - val_accuracy: 0.8322\n",
            "Epoch 522/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.9144 - val_loss: 5.3755 - val_accuracy: 0.7902\n",
            "Epoch 523/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9305 - val_loss: 5.8557 - val_accuracy: 0.8462\n",
            "Epoch 524/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9345 - val_loss: 6.6089 - val_accuracy: 0.8392\n",
            "Epoch 525/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9332 - val_loss: 6.1495 - val_accuracy: 0.8392\n",
            "Epoch 526/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9318 - val_loss: 5.8663 - val_accuracy: 0.8392\n",
            "Epoch 527/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9225 - val_loss: 7.1608 - val_accuracy: 0.8322\n",
            "Epoch 528/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9278 - val_loss: 6.4904 - val_accuracy: 0.8392\n",
            "Epoch 529/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9291 - val_loss: 6.0989 - val_accuracy: 0.8462\n",
            "Epoch 530/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9278 - val_loss: 7.5435 - val_accuracy: 0.8462\n",
            "Epoch 531/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9278 - val_loss: 6.1615 - val_accuracy: 0.8531\n",
            "Epoch 532/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 6.2961 - val_accuracy: 0.8392\n",
            "Epoch 533/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.9305 - val_loss: 3.8094 - val_accuracy: 0.8252\n",
            "Epoch 534/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9358 - val_loss: 5.2847 - val_accuracy: 0.8252\n",
            "Epoch 535/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9345 - val_loss: 5.7011 - val_accuracy: 0.8392\n",
            "Epoch 536/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9278 - val_loss: 5.7822 - val_accuracy: 0.8322\n",
            "Epoch 537/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9305 - val_loss: 5.6066 - val_accuracy: 0.8392\n",
            "Epoch 538/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 1.1072 - accuracy: 0.9251 - val_loss: 5.8977 - val_accuracy: 0.8322\n",
            "Epoch 539/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9318 - val_loss: 5.8808 - val_accuracy: 0.8462\n",
            "Epoch 540/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9291 - val_loss: 6.0710 - val_accuracy: 0.8182\n",
            "Epoch 541/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9278 - val_loss: 5.5620 - val_accuracy: 0.8182\n",
            "Epoch 542/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9305 - val_loss: 5.9387 - val_accuracy: 0.8112\n",
            "Epoch 543/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9291 - val_loss: 6.1595 - val_accuracy: 0.8322\n",
            "Epoch 544/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9278 - val_loss: 7.1569 - val_accuracy: 0.8322\n",
            "Epoch 545/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9318 - val_loss: 7.5788 - val_accuracy: 0.8252\n",
            "Epoch 546/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9305 - val_loss: 7.1320 - val_accuracy: 0.8462\n",
            "Epoch 547/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9345 - val_loss: 7.0438 - val_accuracy: 0.8182\n",
            "Epoch 548/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9278 - val_loss: 11.4664 - val_accuracy: 0.8112\n",
            "Epoch 549/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9251 - val_loss: 7.5262 - val_accuracy: 0.8182\n",
            "Epoch 550/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9332 - val_loss: 7.0524 - val_accuracy: 0.8252\n",
            "Epoch 551/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9278 - val_loss: 6.5903 - val_accuracy: 0.8252\n",
            "Epoch 552/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9278 - val_loss: 7.3967 - val_accuracy: 0.8042\n",
            "Epoch 553/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9305 - val_loss: 8.4769 - val_accuracy: 0.8042\n",
            "Epoch 554/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9225 - val_loss: 7.8802 - val_accuracy: 0.8112\n",
            "Epoch 555/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9305 - val_loss: 7.5306 - val_accuracy: 0.8042\n",
            "Epoch 556/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9332 - val_loss: 9.1807 - val_accuracy: 0.8042\n",
            "Epoch 557/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9278 - val_loss: 8.5032 - val_accuracy: 0.8042\n",
            "Epoch 558/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9291 - val_loss: 8.6317 - val_accuracy: 0.7972\n",
            "Epoch 559/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 7.7628 - val_accuracy: 0.8112\n",
            "Epoch 560/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9225 - val_loss: 7.7009 - val_accuracy: 0.8322\n",
            "Epoch 561/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9278 - val_loss: 6.6035 - val_accuracy: 0.8392\n",
            "Epoch 562/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.7164 - accuracy: 0.9198 - val_loss: 5.6385 - val_accuracy: 0.8112\n",
            "Epoch 563/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9332 - val_loss: 6.2998 - val_accuracy: 0.8112\n",
            "Epoch 564/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9305 - val_loss: 6.6016 - val_accuracy: 0.8182\n",
            "Epoch 565/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9291 - val_loss: 6.3682 - val_accuracy: 0.8252\n",
            "Epoch 566/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9332 - val_loss: 6.8139 - val_accuracy: 0.8252\n",
            "Epoch 567/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9291 - val_loss: 6.4398 - val_accuracy: 0.8182\n",
            "Epoch 568/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9332 - val_loss: 7.8259 - val_accuracy: 0.7902\n",
            "Epoch 569/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9291 - val_loss: 8.5900 - val_accuracy: 0.8182\n",
            "Epoch 570/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9305 - val_loss: 9.4837 - val_accuracy: 0.8182\n",
            "Epoch 571/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.9265 - val_loss: 7.5800 - val_accuracy: 0.8252\n",
            "Epoch 572/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9291 - val_loss: 8.6543 - val_accuracy: 0.8112\n",
            "Epoch 573/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2159 - accuracy: 0.9305 - val_loss: 9.4718 - val_accuracy: 0.8252\n",
            "Epoch 574/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9318 - val_loss: 7.8988 - val_accuracy: 0.8322\n",
            "Epoch 575/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9291 - val_loss: 7.3123 - val_accuracy: 0.8322\n",
            "Epoch 576/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9332 - val_loss: 8.2517 - val_accuracy: 0.8042\n",
            "Epoch 577/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9291 - val_loss: 9.1142 - val_accuracy: 0.8112\n",
            "Epoch 578/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9278 - val_loss: 9.0414 - val_accuracy: 0.8112\n",
            "Epoch 579/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9305 - val_loss: 9.4001 - val_accuracy: 0.8182\n",
            "Epoch 580/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9305 - val_loss: 10.0262 - val_accuracy: 0.8252\n",
            "Epoch 581/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9265 - val_loss: 8.4836 - val_accuracy: 0.8182\n",
            "Epoch 582/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.9318 - val_loss: 9.6458 - val_accuracy: 0.8252\n",
            "Epoch 583/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9318 - val_loss: 14.3597 - val_accuracy: 0.8042\n",
            "Epoch 584/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.9345 - val_loss: 8.5544 - val_accuracy: 0.8322\n",
            "Epoch 585/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9345 - val_loss: 8.7446 - val_accuracy: 0.8322\n",
            "Epoch 586/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9345 - val_loss: 9.4557 - val_accuracy: 0.8322\n",
            "Epoch 587/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9318 - val_loss: 9.6589 - val_accuracy: 0.8252\n",
            "Epoch 588/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9305 - val_loss: 10.8353 - val_accuracy: 0.8182\n",
            "Epoch 589/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9291 - val_loss: 5.9002 - val_accuracy: 0.8531\n",
            "Epoch 590/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9278 - val_loss: 7.5443 - val_accuracy: 0.8392\n",
            "Epoch 591/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9318 - val_loss: 8.9631 - val_accuracy: 0.8322\n",
            "Epoch 592/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9345 - val_loss: 8.5688 - val_accuracy: 0.8462\n",
            "Epoch 593/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9251 - val_loss: 7.0716 - val_accuracy: 0.8462\n",
            "Epoch 594/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9305 - val_loss: 7.7049 - val_accuracy: 0.8322\n",
            "Epoch 595/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9332 - val_loss: 10.2294 - val_accuracy: 0.8392\n",
            "Epoch 596/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.9251 - val_loss: 6.0177 - val_accuracy: 0.8112\n",
            "Epoch 597/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.9291 - val_loss: 8.5710 - val_accuracy: 0.8112\n",
            "Epoch 598/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9291 - val_loss: 8.6077 - val_accuracy: 0.8182\n",
            "Epoch 599/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9278 - val_loss: 8.5531 - val_accuracy: 0.8462\n",
            "Epoch 600/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9332 - val_loss: 7.7508 - val_accuracy: 0.8182\n",
            "Epoch 601/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.9305 - val_loss: 5.9556 - val_accuracy: 0.8252\n",
            "Epoch 602/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9345 - val_loss: 7.2462 - val_accuracy: 0.8322\n",
            "Epoch 603/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1684 - accuracy: 0.9332 - val_loss: 7.6447 - val_accuracy: 0.8112\n",
            "Epoch 604/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9265 - val_loss: 7.8647 - val_accuracy: 0.8112\n",
            "Epoch 605/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9278 - val_loss: 7.6429 - val_accuracy: 0.8252\n",
            "Epoch 606/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9318 - val_loss: 8.7744 - val_accuracy: 0.8112\n",
            "Epoch 607/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9291 - val_loss: 8.2325 - val_accuracy: 0.8252\n",
            "Epoch 608/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.9318 - val_loss: 6.8971 - val_accuracy: 0.7972\n",
            "Epoch 609/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9278 - val_loss: 7.5351 - val_accuracy: 0.7972\n",
            "Epoch 610/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9291 - val_loss: 7.8601 - val_accuracy: 0.8112\n",
            "Epoch 611/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9385 - val_loss: 7.8342 - val_accuracy: 0.8182\n",
            "Epoch 612/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.9238 - val_loss: 9.4553 - val_accuracy: 0.8252\n",
            "Epoch 613/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.9305 - val_loss: 13.0561 - val_accuracy: 0.8112\n",
            "Epoch 614/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.9318 - val_loss: 6.5988 - val_accuracy: 0.8252\n",
            "Epoch 615/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9385 - val_loss: 7.3719 - val_accuracy: 0.8182\n",
            "Epoch 616/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9305 - val_loss: 7.0455 - val_accuracy: 0.8112\n",
            "Epoch 617/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9332 - val_loss: 9.5124 - val_accuracy: 0.8182\n",
            "Epoch 618/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9225 - val_loss: 8.9228 - val_accuracy: 0.8392\n",
            "Epoch 619/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9278 - val_loss: 6.6389 - val_accuracy: 0.8112\n",
            "Epoch 620/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9278 - val_loss: 12.0744 - val_accuracy: 0.8182\n",
            "Epoch 621/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9332 - val_loss: 6.3527 - val_accuracy: 0.8182\n",
            "Epoch 622/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.9305 - val_loss: 7.0844 - val_accuracy: 0.8322\n",
            "Epoch 623/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9332 - val_loss: 7.0987 - val_accuracy: 0.8392\n",
            "Epoch 624/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9345 - val_loss: 7.0821 - val_accuracy: 0.8392\n",
            "Epoch 625/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.9211 - val_loss: 5.7564 - val_accuracy: 0.8182\n",
            "Epoch 626/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9332 - val_loss: 5.8617 - val_accuracy: 0.8182\n",
            "Epoch 627/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9332 - val_loss: 5.7866 - val_accuracy: 0.8322\n",
            "Epoch 628/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9318 - val_loss: 5.9952 - val_accuracy: 0.8252\n",
            "Epoch 629/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9265 - val_loss: 5.5914 - val_accuracy: 0.8042\n",
            "Epoch 630/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9305 - val_loss: 6.7034 - val_accuracy: 0.8112\n",
            "Epoch 631/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.9305 - val_loss: 6.8081 - val_accuracy: 0.8252\n",
            "Epoch 632/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9278 - val_loss: 6.3346 - val_accuracy: 0.8322\n",
            "Epoch 633/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9305 - val_loss: 6.3813 - val_accuracy: 0.8462\n",
            "Epoch 634/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9318 - val_loss: 6.7102 - val_accuracy: 0.8392\n",
            "Epoch 635/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9305 - val_loss: 6.1887 - val_accuracy: 0.8601\n",
            "Epoch 636/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9265 - val_loss: 9.5844 - val_accuracy: 0.8112\n",
            "Epoch 637/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9238 - val_loss: 8.3755 - val_accuracy: 0.8462\n",
            "Epoch 638/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9265 - val_loss: 8.2943 - val_accuracy: 0.8531\n",
            "Epoch 639/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9291 - val_loss: 8.2825 - val_accuracy: 0.8462\n",
            "Epoch 640/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9318 - val_loss: 9.4975 - val_accuracy: 0.8601\n",
            "Epoch 641/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9305 - val_loss: 7.2904 - val_accuracy: 0.8322\n",
            "Epoch 642/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9265 - val_loss: 8.8250 - val_accuracy: 0.8252\n",
            "Epoch 643/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.9278 - val_loss: 11.4880 - val_accuracy: 0.8252\n",
            "Epoch 644/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.9345 - val_loss: 9.5501 - val_accuracy: 0.8322\n",
            "Epoch 645/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9358 - val_loss: 9.2589 - val_accuracy: 0.8182\n",
            "Epoch 646/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9345 - val_loss: 9.5321 - val_accuracy: 0.8252\n",
            "Epoch 647/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9291 - val_loss: 10.2234 - val_accuracy: 0.8322\n",
            "Epoch 648/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9305 - val_loss: 8.6484 - val_accuracy: 0.8322\n",
            "Epoch 649/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9278 - val_loss: 11.1561 - val_accuracy: 0.8112\n",
            "Epoch 650/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.9318 - val_loss: 7.8533 - val_accuracy: 0.8322\n",
            "Epoch 651/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9318 - val_loss: 9.3887 - val_accuracy: 0.8392\n",
            "Epoch 652/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9358 - val_loss: 10.2526 - val_accuracy: 0.8182\n",
            "Epoch 653/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7695 - accuracy: 0.9171 - val_loss: 6.2378 - val_accuracy: 0.8531\n",
            "Epoch 654/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.9345 - val_loss: 6.6901 - val_accuracy: 0.8392\n",
            "Epoch 655/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9345 - val_loss: 7.3717 - val_accuracy: 0.8252\n",
            "Epoch 656/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9318 - val_loss: 6.8435 - val_accuracy: 0.8392\n",
            "Epoch 657/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9265 - val_loss: 3.8504 - val_accuracy: 0.8462\n",
            "Epoch 658/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.9238 - val_loss: 6.6878 - val_accuracy: 0.8322\n",
            "Epoch 659/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9345 - val_loss: 6.8956 - val_accuracy: 0.8322\n",
            "Epoch 660/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9358 - val_loss: 7.4479 - val_accuracy: 0.8322\n",
            "Epoch 661/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9318 - val_loss: 7.6670 - val_accuracy: 0.8112\n",
            "Epoch 662/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9291 - val_loss: 7.1754 - val_accuracy: 0.8392\n",
            "Epoch 663/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9318 - val_loss: 7.9551 - val_accuracy: 0.8462\n",
            "Epoch 664/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9332 - val_loss: 7.0382 - val_accuracy: 0.8462\n",
            "Epoch 665/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9278 - val_loss: 8.8551 - val_accuracy: 0.8462\n",
            "Epoch 666/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9238 - val_loss: 8.5194 - val_accuracy: 0.8601\n",
            "Epoch 667/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9332 - val_loss: 9.1550 - val_accuracy: 0.8322\n",
            "Epoch 668/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9318 - val_loss: 8.9310 - val_accuracy: 0.8392\n",
            "Epoch 669/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9345 - val_loss: 10.2838 - val_accuracy: 0.8322\n",
            "Epoch 670/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9358 - val_loss: 8.9485 - val_accuracy: 0.8252\n",
            "Epoch 671/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9332 - val_loss: 8.3195 - val_accuracy: 0.8182\n",
            "Epoch 672/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9278 - val_loss: 9.3432 - val_accuracy: 0.8252\n",
            "Epoch 673/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9265 - val_loss: 5.6148 - val_accuracy: 0.8322\n",
            "Epoch 674/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9385 - val_loss: 6.1069 - val_accuracy: 0.8252\n",
            "Epoch 675/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9305 - val_loss: 7.6439 - val_accuracy: 0.8042\n",
            "Epoch 676/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9265 - val_loss: 13.9412 - val_accuracy: 0.8042\n",
            "Epoch 677/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.9225 - val_loss: 8.1582 - val_accuracy: 0.8462\n",
            "Epoch 678/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9385 - val_loss: 9.0600 - val_accuracy: 0.8462\n",
            "Epoch 679/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9318 - val_loss: 8.3971 - val_accuracy: 0.8392\n",
            "Epoch 680/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9332 - val_loss: 8.5604 - val_accuracy: 0.8392\n",
            "Epoch 681/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9291 - val_loss: 8.8541 - val_accuracy: 0.8671\n",
            "Epoch 682/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9318 - val_loss: 10.1477 - val_accuracy: 0.8252\n",
            "Epoch 683/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9278 - val_loss: 6.0130 - val_accuracy: 0.8462\n",
            "Epoch 684/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.9318 - val_loss: 6.7684 - val_accuracy: 0.8462\n",
            "Epoch 685/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9358 - val_loss: 5.4173 - val_accuracy: 0.8322\n",
            "Epoch 686/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9345 - val_loss: 5.4653 - val_accuracy: 0.8322\n",
            "Epoch 687/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9372 - val_loss: 6.5278 - val_accuracy: 0.8252\n",
            "Epoch 688/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9211 - val_loss: 5.1169 - val_accuracy: 0.8392\n",
            "Epoch 689/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9305 - val_loss: 5.6081 - val_accuracy: 0.8322\n",
            "Epoch 690/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9318 - val_loss: 8.6948 - val_accuracy: 0.8322\n",
            "Epoch 691/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9332 - val_loss: 8.4997 - val_accuracy: 0.8392\n",
            "Epoch 692/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9291 - val_loss: 8.1657 - val_accuracy: 0.8252\n",
            "Epoch 693/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9291 - val_loss: 7.7188 - val_accuracy: 0.8322\n",
            "Epoch 694/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.9238 - val_loss: 8.7030 - val_accuracy: 0.8601\n",
            "Epoch 695/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9332 - val_loss: 10.0522 - val_accuracy: 0.8322\n",
            "Epoch 696/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9332 - val_loss: 9.7526 - val_accuracy: 0.8601\n",
            "Epoch 697/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2358 - accuracy: 0.9291 - val_loss: 9.7622 - val_accuracy: 0.8252\n",
            "Epoch 698/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9305 - val_loss: 9.0355 - val_accuracy: 0.8322\n",
            "Epoch 699/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9385 - val_loss: 9.1075 - val_accuracy: 0.8322\n",
            "Epoch 700/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9265 - val_loss: 9.5347 - val_accuracy: 0.8112\n",
            "Epoch 701/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.9278 - val_loss: 10.7406 - val_accuracy: 0.8252\n",
            "Epoch 702/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9305 - val_loss: 11.0154 - val_accuracy: 0.8531\n",
            "Epoch 703/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9305 - val_loss: 12.0807 - val_accuracy: 0.8182\n",
            "Epoch 704/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9305 - val_loss: 11.4265 - val_accuracy: 0.8182\n",
            "Epoch 705/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.9332 - val_loss: 11.5150 - val_accuracy: 0.8042\n",
            "Epoch 706/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9265 - val_loss: 11.9527 - val_accuracy: 0.8182\n",
            "Epoch 707/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9238 - val_loss: 11.0339 - val_accuracy: 0.8252\n",
            "Epoch 708/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9291 - val_loss: 9.9220 - val_accuracy: 0.8182\n",
            "Epoch 709/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9238 - val_loss: 9.0511 - val_accuracy: 0.8322\n",
            "Epoch 710/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9372 - val_loss: 9.8679 - val_accuracy: 0.8042\n",
            "Epoch 711/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.9238 - val_loss: 16.6506 - val_accuracy: 0.7902\n",
            "Epoch 712/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.9238 - val_loss: 10.9570 - val_accuracy: 0.8252\n",
            "Epoch 713/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9385 - val_loss: 12.1674 - val_accuracy: 0.8042\n",
            "Epoch 714/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9398 - val_loss: 12.9980 - val_accuracy: 0.8042\n",
            "Epoch 715/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9332 - val_loss: 14.5150 - val_accuracy: 0.8112\n",
            "Epoch 716/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9345 - val_loss: 13.4594 - val_accuracy: 0.8112\n",
            "Epoch 717/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.9158 - val_loss: 13.9309 - val_accuracy: 0.8182\n",
            "Epoch 718/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9398 - val_loss: 15.6498 - val_accuracy: 0.8112\n",
            "Epoch 719/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9345 - val_loss: 15.8576 - val_accuracy: 0.7972\n",
            "Epoch 720/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9332 - val_loss: 15.5817 - val_accuracy: 0.8392\n",
            "Epoch 721/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9291 - val_loss: 14.2657 - val_accuracy: 0.8392\n",
            "Epoch 722/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.9158 - val_loss: 9.5828 - val_accuracy: 0.8392\n",
            "Epoch 723/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9358 - val_loss: 11.1023 - val_accuracy: 0.8252\n",
            "Epoch 724/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9345 - val_loss: 11.0691 - val_accuracy: 0.8322\n",
            "Epoch 725/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9332 - val_loss: 10.2848 - val_accuracy: 0.8462\n",
            "Epoch 726/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9345 - val_loss: 12.0329 - val_accuracy: 0.8322\n",
            "Epoch 727/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9318 - val_loss: 12.0368 - val_accuracy: 0.8392\n",
            "Epoch 728/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9305 - val_loss: 12.5790 - val_accuracy: 0.8322\n",
            "Epoch 729/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9358 - val_loss: 13.8096 - val_accuracy: 0.8112\n",
            "Epoch 730/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9318 - val_loss: 14.7097 - val_accuracy: 0.8322\n",
            "Epoch 731/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9372 - val_loss: 14.9838 - val_accuracy: 0.7902\n",
            "Epoch 732/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9372 - val_loss: 13.3324 - val_accuracy: 0.7972\n",
            "Epoch 733/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.9278 - val_loss: 9.4616 - val_accuracy: 0.8252\n",
            "Epoch 734/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.9291 - val_loss: 8.3792 - val_accuracy: 0.8462\n",
            "Epoch 735/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.9345 - val_loss: 10.6063 - val_accuracy: 0.8322\n",
            "Epoch 736/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9358 - val_loss: 9.9913 - val_accuracy: 0.8392\n",
            "Epoch 737/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9358 - val_loss: 11.4189 - val_accuracy: 0.8392\n",
            "Epoch 738/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9385 - val_loss: 12.7585 - val_accuracy: 0.8182\n",
            "Epoch 739/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.9265 - val_loss: 10.8223 - val_accuracy: 0.8322\n",
            "Epoch 740/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9385 - val_loss: 11.3530 - val_accuracy: 0.8462\n",
            "Epoch 741/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9345 - val_loss: 11.8842 - val_accuracy: 0.8392\n",
            "Epoch 742/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9345 - val_loss: 11.1989 - val_accuracy: 0.8182\n",
            "Epoch 743/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9358 - val_loss: 9.5402 - val_accuracy: 0.8392\n",
            "Epoch 744/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9332 - val_loss: 10.3862 - val_accuracy: 0.8392\n",
            "Epoch 745/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9305 - val_loss: 5.5499 - val_accuracy: 0.8462\n",
            "Epoch 746/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.9158 - val_loss: 10.1755 - val_accuracy: 0.8322\n",
            "Epoch 747/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9398 - val_loss: 10.2346 - val_accuracy: 0.8322\n",
            "Epoch 748/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9358 - val_loss: 10.8503 - val_accuracy: 0.8252\n",
            "Epoch 749/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9358 - val_loss: 9.3566 - val_accuracy: 0.8392\n",
            "Epoch 750/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9358 - val_loss: 7.6538 - val_accuracy: 0.8462\n",
            "Epoch 751/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9345 - val_loss: 10.6552 - val_accuracy: 0.8182\n",
            "Epoch 752/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 1.0385 - accuracy: 0.9318 - val_loss: 8.3527 - val_accuracy: 0.8182\n",
            "Epoch 753/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9332 - val_loss: 8.9698 - val_accuracy: 0.8392\n",
            "Epoch 754/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9332 - val_loss: 9.6856 - val_accuracy: 0.8112\n",
            "Epoch 755/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9332 - val_loss: 10.1796 - val_accuracy: 0.8182\n",
            "Epoch 756/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9332 - val_loss: 9.2834 - val_accuracy: 0.8252\n",
            "Epoch 757/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9318 - val_loss: 9.1659 - val_accuracy: 0.8322\n",
            "Epoch 758/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9305 - val_loss: 10.2543 - val_accuracy: 0.8112\n",
            "Epoch 759/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9291 - val_loss: 11.0039 - val_accuracy: 0.8322\n",
            "Epoch 760/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9358 - val_loss: 9.8098 - val_accuracy: 0.7902\n",
            "Epoch 761/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9332 - val_loss: 9.8812 - val_accuracy: 0.8112\n",
            "Epoch 762/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9385 - val_loss: 9.6671 - val_accuracy: 0.8042\n",
            "Epoch 763/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.9265 - val_loss: 9.5464 - val_accuracy: 0.8322\n",
            "Epoch 764/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9385 - val_loss: 9.8444 - val_accuracy: 0.8462\n",
            "Epoch 765/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9358 - val_loss: 9.4259 - val_accuracy: 0.8322\n",
            "Epoch 766/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9385 - val_loss: 9.6691 - val_accuracy: 0.8392\n",
            "Epoch 767/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9332 - val_loss: 9.8773 - val_accuracy: 0.8392\n",
            "Epoch 768/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9291 - val_loss: 10.9151 - val_accuracy: 0.8462\n",
            "Epoch 769/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.9318 - val_loss: 8.7958 - val_accuracy: 0.8042\n",
            "Epoch 770/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 1.4354 - accuracy: 0.9291 - val_loss: 4.1752 - val_accuracy: 0.8462\n",
            "Epoch 771/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9412 - val_loss: 4.4852 - val_accuracy: 0.8462\n",
            "Epoch 772/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9385 - val_loss: 4.5282 - val_accuracy: 0.8462\n",
            "Epoch 773/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9332 - val_loss: 5.0551 - val_accuracy: 0.8322\n",
            "Epoch 774/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.9291 - val_loss: 4.2527 - val_accuracy: 0.8182\n",
            "Epoch 775/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.9372 - val_loss: 10.5748 - val_accuracy: 0.8112\n",
            "Epoch 776/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9398 - val_loss: 9.4679 - val_accuracy: 0.8531\n",
            "Epoch 777/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9385 - val_loss: 10.1933 - val_accuracy: 0.8392\n",
            "Epoch 778/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9358 - val_loss: 10.4154 - val_accuracy: 0.8392\n",
            "Epoch 779/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9318 - val_loss: 8.4399 - val_accuracy: 0.8182\n",
            "Epoch 780/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9318 - val_loss: 8.4601 - val_accuracy: 0.8322\n",
            "Epoch 781/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9412 - val_loss: 11.6501 - val_accuracy: 0.8112\n",
            "Epoch 782/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9372 - val_loss: 8.5968 - val_accuracy: 0.8392\n",
            "Epoch 783/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9318 - val_loss: 9.8339 - val_accuracy: 0.8322\n",
            "Epoch 784/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9251 - val_loss: 7.1861 - val_accuracy: 0.8322\n",
            "Epoch 785/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9318 - val_loss: 8.2201 - val_accuracy: 0.8252\n",
            "Epoch 786/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9265 - val_loss: 6.2277 - val_accuracy: 0.8462\n",
            "Epoch 787/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9332 - val_loss: 7.5002 - val_accuracy: 0.8462\n",
            "Epoch 788/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9345 - val_loss: 8.7670 - val_accuracy: 0.8112\n",
            "Epoch 789/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9358 - val_loss: 10.6150 - val_accuracy: 0.8112\n",
            "Epoch 790/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9332 - val_loss: 9.3831 - val_accuracy: 0.8322\n",
            "Epoch 791/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7789 - accuracy: 0.9225 - val_loss: 6.4016 - val_accuracy: 0.8112\n",
            "Epoch 792/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1876 - accuracy: 0.9345 - val_loss: 5.6081 - val_accuracy: 0.8182\n",
            "Epoch 793/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9385 - val_loss: 6.0166 - val_accuracy: 0.8252\n",
            "Epoch 794/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9398 - val_loss: 6.1982 - val_accuracy: 0.8182\n",
            "Epoch 795/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.9238 - val_loss: 7.0909 - val_accuracy: 0.8462\n",
            "Epoch 796/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9398 - val_loss: 7.9536 - val_accuracy: 0.8462\n",
            "Epoch 797/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9278 - val_loss: 7.6812 - val_accuracy: 0.8531\n",
            "Epoch 798/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9278 - val_loss: 6.9511 - val_accuracy: 0.8392\n",
            "Epoch 799/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9332 - val_loss: 8.4187 - val_accuracy: 0.8392\n",
            "Epoch 800/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1828 - accuracy: 0.9291 - val_loss: 7.7651 - val_accuracy: 0.8462\n",
            "Epoch 801/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9345 - val_loss: 10.1924 - val_accuracy: 0.8392\n",
            "Epoch 802/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9358 - val_loss: 9.9033 - val_accuracy: 0.8252\n",
            "Epoch 803/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9318 - val_loss: 9.5232 - val_accuracy: 0.8042\n",
            "Epoch 804/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.9238 - val_loss: 5.6171 - val_accuracy: 0.8252\n",
            "Epoch 805/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9385 - val_loss: 5.6689 - val_accuracy: 0.8252\n",
            "Epoch 806/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9398 - val_loss: 6.3175 - val_accuracy: 0.8322\n",
            "Epoch 807/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9385 - val_loss: 5.9578 - val_accuracy: 0.8392\n",
            "Epoch 808/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9358 - val_loss: 6.4303 - val_accuracy: 0.8112\n",
            "Epoch 809/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9291 - val_loss: 5.9528 - val_accuracy: 0.8322\n",
            "Epoch 810/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9291 - val_loss: 5.3308 - val_accuracy: 0.8392\n",
            "Epoch 811/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9398 - val_loss: 5.2394 - val_accuracy: 0.8531\n",
            "Epoch 812/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9398 - val_loss: 5.4061 - val_accuracy: 0.8392\n",
            "Epoch 813/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9358 - val_loss: 5.1212 - val_accuracy: 0.8462\n",
            "Epoch 814/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9318 - val_loss: 5.1200 - val_accuracy: 0.8462\n",
            "Epoch 815/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9318 - val_loss: 6.3929 - val_accuracy: 0.8322\n",
            "Epoch 816/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.9305 - val_loss: 5.3697 - val_accuracy: 0.8741\n",
            "Epoch 817/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9412 - val_loss: 6.8608 - val_accuracy: 0.8462\n",
            "Epoch 818/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9358 - val_loss: 5.0727 - val_accuracy: 0.8252\n",
            "Epoch 819/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9305 - val_loss: 7.4216 - val_accuracy: 0.8462\n",
            "Epoch 820/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9318 - val_loss: 7.0087 - val_accuracy: 0.8112\n",
            "Epoch 821/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9398 - val_loss: 6.7138 - val_accuracy: 0.8392\n",
            "Epoch 822/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9358 - val_loss: 6.8725 - val_accuracy: 0.8112\n",
            "Epoch 823/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9372 - val_loss: 7.5304 - val_accuracy: 0.8112\n",
            "Epoch 824/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9345 - val_loss: 7.5937 - val_accuracy: 0.8322\n",
            "Epoch 825/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9291 - val_loss: 6.0896 - val_accuracy: 0.8322\n",
            "Epoch 826/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9278 - val_loss: 8.9212 - val_accuracy: 0.8182\n",
            "Epoch 827/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9345 - val_loss: 13.7695 - val_accuracy: 0.8182\n",
            "Epoch 828/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9398 - val_loss: 12.9129 - val_accuracy: 0.8601\n",
            "Epoch 829/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9372 - val_loss: 13.0098 - val_accuracy: 0.8462\n",
            "Epoch 830/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9358 - val_loss: 12.4501 - val_accuracy: 0.8392\n",
            "Epoch 831/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9412 - val_loss: 14.0174 - val_accuracy: 0.8392\n",
            "Epoch 832/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9345 - val_loss: 13.6701 - val_accuracy: 0.8252\n",
            "Epoch 833/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9318 - val_loss: 11.8268 - val_accuracy: 0.8392\n",
            "Epoch 834/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9358 - val_loss: 13.3629 - val_accuracy: 0.8182\n",
            "Epoch 835/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9425 - val_loss: 13.8766 - val_accuracy: 0.8112\n",
            "Epoch 836/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9318 - val_loss: 13.3407 - val_accuracy: 0.8322\n",
            "Epoch 837/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9385 - val_loss: 14.1451 - val_accuracy: 0.8252\n",
            "Epoch 838/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9385 - val_loss: 13.8697 - val_accuracy: 0.8252\n",
            "Epoch 839/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9358 - val_loss: 14.0951 - val_accuracy: 0.8392\n",
            "Epoch 840/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2058 - accuracy: 0.9425 - val_loss: 9.9755 - val_accuracy: 0.8322\n",
            "Epoch 841/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9385 - val_loss: 11.8124 - val_accuracy: 0.8112\n",
            "Epoch 842/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9291 - val_loss: 12.1729 - val_accuracy: 0.8182\n",
            "Epoch 843/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9358 - val_loss: 11.4285 - val_accuracy: 0.8182\n",
            "Epoch 844/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9345 - val_loss: 11.3052 - val_accuracy: 0.8462\n",
            "Epoch 845/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9398 - val_loss: 10.4844 - val_accuracy: 0.8392\n",
            "Epoch 846/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9372 - val_loss: 11.0618 - val_accuracy: 0.8252\n",
            "Epoch 847/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9372 - val_loss: 10.4588 - val_accuracy: 0.8392\n",
            "Epoch 848/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.9251 - val_loss: 8.0766 - val_accuracy: 0.8252\n",
            "Epoch 849/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.9412 - val_loss: 7.9242 - val_accuracy: 0.8741\n",
            "Epoch 850/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9412 - val_loss: 8.4717 - val_accuracy: 0.8462\n",
            "Epoch 851/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9398 - val_loss: 8.5945 - val_accuracy: 0.8531\n",
            "Epoch 852/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9345 - val_loss: 8.8948 - val_accuracy: 0.8392\n",
            "Epoch 853/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9372 - val_loss: 10.7833 - val_accuracy: 0.8601\n",
            "Epoch 854/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9332 - val_loss: 8.5463 - val_accuracy: 0.8252\n",
            "Epoch 855/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.9938 - accuracy: 0.9251 - val_loss: 10.6161 - val_accuracy: 0.8322\n",
            "Epoch 856/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9372 - val_loss: 11.1248 - val_accuracy: 0.8531\n",
            "Epoch 857/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9452 - val_loss: 11.3668 - val_accuracy: 0.8601\n",
            "Epoch 858/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9412 - val_loss: 11.9712 - val_accuracy: 0.8462\n",
            "Epoch 859/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9345 - val_loss: 9.6586 - val_accuracy: 0.8462\n",
            "Epoch 860/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9345 - val_loss: 12.1910 - val_accuracy: 0.8252\n",
            "Epoch 861/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9345 - val_loss: 10.5619 - val_accuracy: 0.8741\n",
            "Epoch 862/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9412 - val_loss: 12.4645 - val_accuracy: 0.8531\n",
            "Epoch 863/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9251 - val_loss: 8.2084 - val_accuracy: 0.8531\n",
            "Epoch 864/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9225 - val_loss: 9.8120 - val_accuracy: 0.8322\n",
            "Epoch 865/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9398 - val_loss: 11.2670 - val_accuracy: 0.8322\n",
            "Epoch 866/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9425 - val_loss: 12.2258 - val_accuracy: 0.8252\n",
            "Epoch 867/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9291 - val_loss: 10.4970 - val_accuracy: 0.8182\n",
            "Epoch 868/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9385 - val_loss: 12.2824 - val_accuracy: 0.8042\n",
            "Epoch 869/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9305 - val_loss: 12.2415 - val_accuracy: 0.8252\n",
            "Epoch 870/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9398 - val_loss: 9.7837 - val_accuracy: 0.8322\n",
            "Epoch 871/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9398 - val_loss: 11.3366 - val_accuracy: 0.8252\n",
            "Epoch 872/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.9291 - val_loss: 8.7394 - val_accuracy: 0.8042\n",
            "Epoch 873/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9358 - val_loss: 13.5689 - val_accuracy: 0.8252\n",
            "Epoch 874/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9358 - val_loss: 12.0328 - val_accuracy: 0.7902\n",
            "Epoch 875/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.9318 - val_loss: 11.2493 - val_accuracy: 0.8252\n",
            "Epoch 876/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9439 - val_loss: 9.3289 - val_accuracy: 0.8531\n",
            "Epoch 877/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9425 - val_loss: 13.2913 - val_accuracy: 0.7972\n",
            "Epoch 878/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9385 - val_loss: 12.1990 - val_accuracy: 0.8252\n",
            "Epoch 879/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9412 - val_loss: 11.8972 - val_accuracy: 0.8322\n",
            "Epoch 880/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9385 - val_loss: 16.3849 - val_accuracy: 0.8322\n",
            "Epoch 881/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9385 - val_loss: 10.8017 - val_accuracy: 0.8252\n",
            "Epoch 882/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9372 - val_loss: 12.2476 - val_accuracy: 0.8182\n",
            "Epoch 883/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9398 - val_loss: 13.3441 - val_accuracy: 0.8322\n",
            "Epoch 884/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9358 - val_loss: 12.0579 - val_accuracy: 0.8182\n",
            "Epoch 885/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9398 - val_loss: 14.8572 - val_accuracy: 0.8462\n",
            "Epoch 886/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9412 - val_loss: 12.9942 - val_accuracy: 0.8531\n",
            "Epoch 887/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9439 - val_loss: 13.3904 - val_accuracy: 0.8462\n",
            "Epoch 888/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9372 - val_loss: 13.1812 - val_accuracy: 0.8182\n",
            "Epoch 889/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9358 - val_loss: 15.6819 - val_accuracy: 0.8252\n",
            "Epoch 890/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9372 - val_loss: 13.1388 - val_accuracy: 0.8392\n",
            "Epoch 891/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9425 - val_loss: 13.2766 - val_accuracy: 0.8531\n",
            "Epoch 892/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9425 - val_loss: 15.0028 - val_accuracy: 0.8322\n",
            "Epoch 893/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9372 - val_loss: 12.6614 - val_accuracy: 0.8322\n",
            "Epoch 894/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9425 - val_loss: 12.0618 - val_accuracy: 0.8601\n",
            "Epoch 895/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9452 - val_loss: 12.5920 - val_accuracy: 0.8531\n",
            "Epoch 896/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9372 - val_loss: 12.9270 - val_accuracy: 0.8671\n",
            "Epoch 897/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9291 - val_loss: 10.4136 - val_accuracy: 0.8601\n",
            "Epoch 898/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9425 - val_loss: 11.1858 - val_accuracy: 0.8462\n",
            "Epoch 899/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9452 - val_loss: 10.6918 - val_accuracy: 0.8531\n",
            "Epoch 900/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9425 - val_loss: 12.2743 - val_accuracy: 0.8462\n",
            "Epoch 901/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.9251 - val_loss: 9.3842 - val_accuracy: 0.8601\n",
            "Epoch 902/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9358 - val_loss: 10.6795 - val_accuracy: 0.8462\n",
            "Epoch 903/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9412 - val_loss: 10.2831 - val_accuracy: 0.8531\n",
            "Epoch 904/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9398 - val_loss: 11.0794 - val_accuracy: 0.8531\n",
            "Epoch 905/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9452 - val_loss: 11.5119 - val_accuracy: 0.8462\n",
            "Epoch 906/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9358 - val_loss: 9.4511 - val_accuracy: 0.8252\n",
            "Epoch 907/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.9318 - val_loss: 9.1824 - val_accuracy: 0.8252\n",
            "Epoch 908/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.9332 - val_loss: 9.0239 - val_accuracy: 0.8531\n",
            "Epoch 909/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9412 - val_loss: 10.0354 - val_accuracy: 0.8322\n",
            "Epoch 910/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9425 - val_loss: 9.6738 - val_accuracy: 0.8322\n",
            "Epoch 911/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9398 - val_loss: 11.3371 - val_accuracy: 0.8462\n",
            "Epoch 912/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9439 - val_loss: 11.2053 - val_accuracy: 0.8322\n",
            "Epoch 913/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 1.5376 - accuracy: 0.9358 - val_loss: 6.9237 - val_accuracy: 0.8392\n",
            "Epoch 914/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9452 - val_loss: 6.4217 - val_accuracy: 0.8182\n",
            "Epoch 915/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9452 - val_loss: 6.5902 - val_accuracy: 0.8182\n",
            "Epoch 916/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9452 - val_loss: 6.4460 - val_accuracy: 0.8252\n",
            "Epoch 917/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9398 - val_loss: 7.5493 - val_accuracy: 0.8182\n",
            "Epoch 918/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9385 - val_loss: 6.1905 - val_accuracy: 0.8182\n",
            "Epoch 919/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.9291 - val_loss: 6.6201 - val_accuracy: 0.8252\n",
            "Epoch 920/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9372 - val_loss: 8.3423 - val_accuracy: 0.8462\n",
            "Epoch 921/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9465 - val_loss: 6.0655 - val_accuracy: 0.8531\n",
            "Epoch 922/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9412 - val_loss: 9.2776 - val_accuracy: 0.8112\n",
            "Epoch 923/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9372 - val_loss: 6.3461 - val_accuracy: 0.8392\n",
            "Epoch 924/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9385 - val_loss: 8.7723 - val_accuracy: 0.8182\n",
            "Epoch 925/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9358 - val_loss: 5.8903 - val_accuracy: 0.7692\n",
            "Epoch 926/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9412 - val_loss: 6.6640 - val_accuracy: 0.8252\n",
            "Epoch 927/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9412 - val_loss: 9.7230 - val_accuracy: 0.8252\n",
            "Epoch 928/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9372 - val_loss: 9.1777 - val_accuracy: 0.8112\n",
            "Epoch 929/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.8050 - accuracy: 0.9358 - val_loss: 10.6841 - val_accuracy: 0.8182\n",
            "Epoch 930/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.9412 - val_loss: 10.8927 - val_accuracy: 0.8182\n",
            "Epoch 931/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9465 - val_loss: 10.4197 - val_accuracy: 0.8462\n",
            "Epoch 932/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9465 - val_loss: 10.2712 - val_accuracy: 0.8322\n",
            "Epoch 933/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9398 - val_loss: 10.0860 - val_accuracy: 0.8531\n",
            "Epoch 934/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9439 - val_loss: 8.2208 - val_accuracy: 0.8322\n",
            "Epoch 935/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9332 - val_loss: 6.8236 - val_accuracy: 0.8531\n",
            "Epoch 936/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9251 - val_loss: 8.2150 - val_accuracy: 0.8322\n",
            "Epoch 937/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9398 - val_loss: 9.4553 - val_accuracy: 0.8392\n",
            "Epoch 938/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9398 - val_loss: 10.7817 - val_accuracy: 0.8322\n",
            "Epoch 939/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9372 - val_loss: 10.0285 - val_accuracy: 0.8182\n",
            "Epoch 940/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9412 - val_loss: 14.4876 - val_accuracy: 0.7972\n",
            "Epoch 941/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9439 - val_loss: 8.5976 - val_accuracy: 0.8671\n",
            "Epoch 942/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9412 - val_loss: 8.1929 - val_accuracy: 0.8531\n",
            "Epoch 943/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9398 - val_loss: 10.5300 - val_accuracy: 0.8462\n",
            "Epoch 944/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9452 - val_loss: 9.2090 - val_accuracy: 0.8462\n",
            "Epoch 945/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9385 - val_loss: 11.0954 - val_accuracy: 0.8671\n",
            "Epoch 946/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9318 - val_loss: 7.9524 - val_accuracy: 0.8462\n",
            "Epoch 947/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9412 - val_loss: 9.4183 - val_accuracy: 0.8392\n",
            "Epoch 948/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.9318 - val_loss: 5.2369 - val_accuracy: 0.8601\n",
            "Epoch 949/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9358 - val_loss: 8.4137 - val_accuracy: 0.8601\n",
            "Epoch 950/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9439 - val_loss: 8.1326 - val_accuracy: 0.8462\n",
            "Epoch 951/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9345 - val_loss: 8.7793 - val_accuracy: 0.8462\n",
            "Epoch 952/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9385 - val_loss: 9.1016 - val_accuracy: 0.8531\n",
            "Epoch 953/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9412 - val_loss: 7.8876 - val_accuracy: 0.8462\n",
            "Epoch 954/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9412 - val_loss: 8.4927 - val_accuracy: 0.8112\n",
            "Epoch 955/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9398 - val_loss: 9.0677 - val_accuracy: 0.8252\n",
            "Epoch 956/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9439 - val_loss: 10.2811 - val_accuracy: 0.8322\n",
            "Epoch 957/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9425 - val_loss: 10.6506 - val_accuracy: 0.8462\n",
            "Epoch 958/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9398 - val_loss: 10.9305 - val_accuracy: 0.8322\n",
            "Epoch 959/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9385 - val_loss: 10.9818 - val_accuracy: 0.8322\n",
            "Epoch 960/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9412 - val_loss: 10.9462 - val_accuracy: 0.8392\n",
            "Epoch 961/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9372 - val_loss: 9.6299 - val_accuracy: 0.8252\n",
            "Epoch 962/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9385 - val_loss: 10.5755 - val_accuracy: 0.8182\n",
            "Epoch 963/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9345 - val_loss: 10.0095 - val_accuracy: 0.8392\n",
            "Epoch 964/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.9332 - val_loss: 10.6506 - val_accuracy: 0.8182\n",
            "Epoch 965/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9465 - val_loss: 11.2448 - val_accuracy: 0.8182\n",
            "Epoch 966/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9412 - val_loss: 12.1855 - val_accuracy: 0.8042\n",
            "Epoch 967/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9412 - val_loss: 11.1169 - val_accuracy: 0.8252\n",
            "Epoch 968/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9452 - val_loss: 11.5893 - val_accuracy: 0.8182\n",
            "Epoch 969/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2198 - accuracy: 0.9372 - val_loss: 6.9820 - val_accuracy: 0.8531\n",
            "Epoch 970/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.9358 - val_loss: 9.2201 - val_accuracy: 0.8182\n",
            "Epoch 971/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9385 - val_loss: 8.5230 - val_accuracy: 0.8322\n",
            "Epoch 972/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9385 - val_loss: 8.7946 - val_accuracy: 0.8322\n",
            "Epoch 973/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9412 - val_loss: 8.7635 - val_accuracy: 0.7972\n",
            "Epoch 974/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9345 - val_loss: 6.5710 - val_accuracy: 0.8392\n",
            "Epoch 975/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9398 - val_loss: 7.1248 - val_accuracy: 0.8252\n",
            "Epoch 976/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9372 - val_loss: 9.3821 - val_accuracy: 0.8462\n",
            "Epoch 977/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9385 - val_loss: 14.0784 - val_accuracy: 0.8182\n",
            "Epoch 978/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.9291 - val_loss: 11.2300 - val_accuracy: 0.8252\n",
            "Epoch 979/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9439 - val_loss: 9.5406 - val_accuracy: 0.8252\n",
            "Epoch 980/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9452 - val_loss: 9.2508 - val_accuracy: 0.8322\n",
            "Epoch 981/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9465 - val_loss: 9.7889 - val_accuracy: 0.8182\n",
            "Epoch 982/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9358 - val_loss: 10.2550 - val_accuracy: 0.8182\n",
            "Epoch 983/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9398 - val_loss: 9.4643 - val_accuracy: 0.8392\n",
            "Epoch 984/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9372 - val_loss: 10.0892 - val_accuracy: 0.8322\n",
            "Epoch 985/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9345 - val_loss: 11.3380 - val_accuracy: 0.8601\n",
            "Epoch 986/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9425 - val_loss: 10.3981 - val_accuracy: 0.8531\n",
            "Epoch 987/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9412 - val_loss: 12.3341 - val_accuracy: 0.8392\n",
            "Epoch 988/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9398 - val_loss: 7.8026 - val_accuracy: 0.8322\n",
            "Epoch 989/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.9345 - val_loss: 8.1585 - val_accuracy: 0.8112\n",
            "Epoch 990/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.2623 - accuracy: 0.9385 - val_loss: 10.4267 - val_accuracy: 0.8392\n",
            "Epoch 991/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9398 - val_loss: 9.9306 - val_accuracy: 0.7972\n",
            "Epoch 992/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9425 - val_loss: 10.4789 - val_accuracy: 0.8462\n",
            "Epoch 993/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9372 - val_loss: 8.4221 - val_accuracy: 0.8531\n",
            "Epoch 994/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9425 - val_loss: 7.5731 - val_accuracy: 0.8392\n",
            "Epoch 995/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9398 - val_loss: 7.0776 - val_accuracy: 0.8252\n",
            "Epoch 996/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9372 - val_loss: 8.7048 - val_accuracy: 0.6853\n",
            "Epoch 997/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9358 - val_loss: 12.3149 - val_accuracy: 0.8392\n",
            "Epoch 998/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9372 - val_loss: 7.9953 - val_accuracy: 0.8112\n",
            "Epoch 999/1000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9385 - val_loss: 14.1608 - val_accuracy: 0.8322\n",
            "Epoch 1000/1000\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9439 - val_loss: 15.8269 - val_accuracy: 0.8252\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 1.5751 - accuracy: 0.9050\n",
            "0.9050279259681702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFM8l0ch7EEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f00928da-8cb4-49fd-ffc4-e1fba1ef45cb"
      },
      "source": [
        "print('Train accuracy =         94.39% ')\n",
        "print('Validation accuracy =    82.52% ')\n",
        "print('Test accuracy =          90.50% ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy =         94.39% \n",
            "Validation accuracy =    82.52% \n",
            "Test accuracy =          90.50% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbA1W_G-_NQG",
        "colab_type": "text"
      },
      "source": [
        "# **Q2) Classification model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhDrCfGL5GJe",
        "colab_type": "text"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRRq_GtTrOdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebf98f7e-8b12-46f4-e43a-39f783348676"
      },
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)\n",
        "\n",
        "Y_pred = decision_tree.predict(x_test)\n",
        "\n",
        "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
        "print(round(acc_decision_tree,2,), \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OasljpQqtRdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fb7a121-da75-468d-efc2-385fba68217c"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion='gini',splitter='best',min_samples_split=4, min_samples_leaf=1, min_weight_fraction_leaf=0.0, min_impurity_decrease=0.0,presort='deprecated',ccp_alpha=0.0)\n",
        "decision_tree.fit(x_train, y_train)\n",
        "\n",
        "Y_pred = decision_tree.predict(x_test)\n",
        "\n",
        "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
        "print(round(acc_decision_tree,2,), \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzdRkiElwPcA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9cc94ed-e8d1-4ff2-a104-6d403b35ba1b"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion='gini',splitter='best',min_samples_split=6, min_samples_leaf=1, min_weight_fraction_leaf=0.0, min_impurity_decrease=0.0,presort='deprecated',ccp_alpha=0.0)\n",
        "decision_tree.fit(x_val, y_val)\n",
        "\n",
        "Y_pred = decision_tree.predict(x_val)\n",
        "\n",
        "acc_decision_tree = round(decision_tree.score(x_val, y_val) * 100, 2)\n",
        "print(round(acc_decision_tree,2,), \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.26 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxa2x7vCr9Gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feeaa0d8-b619-4fbf-ece3-721fd6f4a713"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion='gini',splitter='best',min_samples_split=7, min_samples_leaf=1, min_weight_fraction_leaf=0.0, min_impurity_decrease=0.0,presort='deprecated',ccp_alpha=0.0)\n",
        "decision_tree.fit(x_test, y_test)\n",
        "\n",
        "Y_pred = decision_tree.predict(x_test)\n",
        "\n",
        "acc_decision_tree = round(decision_tree.score(x_test, y_test) * 100, 2)\n",
        "print(round(acc_decision_tree,2,), \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.62 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeigELy10lGA",
        "colab_type": "text"
      },
      "source": [
        "# **Q3)**\n",
        "\n",
        "Hyperparameter:\n",
        "\n",
        "criterion='gini',\n",
        "\n",
        "splitter='best', \n",
        "\n",
        "max_depth=None, \n",
        "\n",
        "min_samples_split={1,6,7},\n",
        "\n",
        "min_samples_leaf=1, \n",
        "\n",
        "min_weight_fraction_leaf=0.0, \n",
        "\n",
        "min_impurity_decrease=0.0, \n",
        "\n",
        "presort='deprecated', \n",
        "\n",
        "ccp_alpha=0.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwWm2atzCGWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train accuracy =         96.25% ')\n",
        "print('Validation accuracy =    93.26% ')\n",
        "print('Test accuracy =          91.62% ')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}